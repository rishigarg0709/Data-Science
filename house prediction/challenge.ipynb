{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=pd.read_csv(\"Train/Train_data.csv\")\n",
    "dftest=pd.read_csv(\"Test/Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "5         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
       "6         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "7         Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n",
       "8         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "9         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "5     10   2009        WD         Normal     143000  \n",
       "6      8   2007        WD         Normal     307000  \n",
       "7     11   2009        WD         Normal     200000  \n",
       "8      4   2008        WD        Abnorml     129900  \n",
       "9      1   2008        WD         Normal     118000  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col=[]\n",
    "for col in dftrain.columns: \n",
    "    all_col.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "print(len(train_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=dftrain.dropna(axis=1,how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col=[]\n",
    "for col in dftrain.columns: \n",
    "    train_col.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_col=[]\n",
    "for i in range(len(all_col)):\n",
    "    if( all_col[i] not in train_col):\n",
    "        del_col.append(all_col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n"
     ]
    }
   ],
   "source": [
    "print(del_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest=dftest.drop(del_col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=dftrain.values[:,:-1]\n",
    "Y_train=dftrain.values[:,-1]\n",
    "X_test=dftest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 62) (359, 62)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehotencoder = OneHotEncoder() \n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    if(type(X_train[0][i])== str):\n",
    "        X_train[:,i]= le.fit_transform(X_train[:,i]) \n",
    "        \n",
    "#X_train = onehotencoder.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 62)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[1]):\n",
    "    if(type(X_test[0][i])== str):\n",
    "        X_test[:,i]= le.fit_transform(X_test[:,i]) \n",
    "        \n",
    "#X_test = onehotencoder.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest=dftest.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 62) (359, 62)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.metrics import mean_absolute_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               8064      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 172,929\n",
      "Trainable params: 172,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 880 samples, validate on 220 samples\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rishigarg/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "880/880 [==============================] - 2s 2ms/step - loss: 154734.1689 - mean_absolute_error: 154734.1689 - val_loss: 55596.5917 - val_mean_absolute_error: 55596.5917\n",
      "Epoch 2/500\n",
      "880/880 [==============================] - 0s 172us/step - loss: 62149.8310 - mean_absolute_error: 62149.8310 - val_loss: 41701.0358 - val_mean_absolute_error: 41701.0358\n",
      "Epoch 3/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 50169.3894 - mean_absolute_error: 50169.3894 - val_loss: 41550.9398 - val_mean_absolute_error: 41550.9398\n",
      "Epoch 4/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 43381.0849 - mean_absolute_error: 43381.0849 - val_loss: 34277.7701 - val_mean_absolute_error: 34277.7701\n",
      "Epoch 5/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 37056.3520 - mean_absolute_error: 37056.3520 - val_loss: 30794.3721 - val_mean_absolute_error: 30794.3721\n",
      "Epoch 6/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 32504.5248 - mean_absolute_error: 32504.5248 - val_loss: 29314.2591 - val_mean_absolute_error: 29314.2591\n",
      "Epoch 7/500\n",
      "880/880 [==============================] - 0s 171us/step - loss: 32182.9901 - mean_absolute_error: 32182.9901 - val_loss: 28583.3806 - val_mean_absolute_error: 28583.3806\n",
      "Epoch 8/500\n",
      "880/880 [==============================] - 0s 174us/step - loss: 29035.0443 - mean_absolute_error: 29035.0443 - val_loss: 30374.7167 - val_mean_absolute_error: 30374.7167\n",
      "Epoch 9/500\n",
      "880/880 [==============================] - 0s 178us/step - loss: 28334.1602 - mean_absolute_error: 28334.1602 - val_loss: 27568.7188 - val_mean_absolute_error: 27568.7188\n",
      "Epoch 10/500\n",
      "880/880 [==============================] - 0s 173us/step - loss: 27572.5293 - mean_absolute_error: 27572.5293 - val_loss: 27497.2219 - val_mean_absolute_error: 27497.2219\n",
      "Epoch 11/500\n",
      "880/880 [==============================] - 0s 173us/step - loss: 27361.8656 - mean_absolute_error: 27361.8656 - val_loss: 27557.3931 - val_mean_absolute_error: 27557.3931\n",
      "Epoch 12/500\n",
      "880/880 [==============================] - 0s 172us/step - loss: 27793.6095 - mean_absolute_error: 27793.6095 - val_loss: 27388.1876 - val_mean_absolute_error: 27388.1876\n",
      "Epoch 13/500\n",
      "880/880 [==============================] - 0s 171us/step - loss: 27193.4368 - mean_absolute_error: 27193.4368 - val_loss: 30569.6583 - val_mean_absolute_error: 30569.6583\n",
      "Epoch 14/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 27700.6178 - mean_absolute_error: 27700.6178 - val_loss: 27389.4375 - val_mean_absolute_error: 27389.4375\n",
      "Epoch 15/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 26790.5768 - mean_absolute_error: 26790.5768 - val_loss: 27059.3964 - val_mean_absolute_error: 27059.3964\n",
      "Epoch 16/500\n",
      "880/880 [==============================] - 0s 172us/step - loss: 27167.4393 - mean_absolute_error: 27167.4393 - val_loss: 27448.0221 - val_mean_absolute_error: 27448.0221\n",
      "Epoch 17/500\n",
      "880/880 [==============================] - 0s 171us/step - loss: 26080.3577 - mean_absolute_error: 26080.3577 - val_loss: 30108.8116 - val_mean_absolute_error: 30108.8116\n",
      "Epoch 18/500\n",
      "880/880 [==============================] - 0s 168us/step - loss: 26398.0858 - mean_absolute_error: 26398.0858 - val_loss: 26887.0170 - val_mean_absolute_error: 26887.0170\n",
      "Epoch 19/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 27111.3424 - mean_absolute_error: 27111.3424 - val_loss: 29871.2804 - val_mean_absolute_error: 29871.2804\n",
      "Epoch 20/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 26648.3258 - mean_absolute_error: 26648.3258 - val_loss: 26792.2774 - val_mean_absolute_error: 26792.2774\n",
      "Epoch 21/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 26221.9537 - mean_absolute_error: 26221.9537 - val_loss: 31733.1100 - val_mean_absolute_error: 31733.1100\n",
      "Epoch 22/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 26533.8445 - mean_absolute_error: 26533.8445 - val_loss: 27111.6454 - val_mean_absolute_error: 27111.6454\n",
      "Epoch 23/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 26444.9084 - mean_absolute_error: 26444.9084 - val_loss: 35156.6437 - val_mean_absolute_error: 35156.6437\n",
      "Epoch 24/500\n",
      "880/880 [==============================] - 0s 169us/step - loss: 27352.0698 - mean_absolute_error: 27352.0698 - val_loss: 29231.7177 - val_mean_absolute_error: 29231.7177\n",
      "Epoch 25/500\n",
      "880/880 [==============================] - 0s 175us/step - loss: 26773.6888 - mean_absolute_error: 26773.6888 - val_loss: 27521.6299 - val_mean_absolute_error: 27521.6299\n",
      "Epoch 26/500\n",
      "880/880 [==============================] - 0s 176us/step - loss: 26056.3839 - mean_absolute_error: 26056.3839 - val_loss: 26634.0814 - val_mean_absolute_error: 26634.0814\n",
      "Epoch 27/500\n",
      "880/880 [==============================] - 0s 174us/step - loss: 25578.8157 - mean_absolute_error: 25578.8157 - val_loss: 27938.8278 - val_mean_absolute_error: 27938.8278\n",
      "Epoch 28/500\n",
      "880/880 [==============================] - 0s 171us/step - loss: 25961.3663 - mean_absolute_error: 25961.3663 - val_loss: 27241.0801 - val_mean_absolute_error: 27241.0801\n",
      "Epoch 29/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 25326.2606 - mean_absolute_error: 25326.2606 - val_loss: 29585.0815 - val_mean_absolute_error: 29585.0815\n",
      "Epoch 30/500\n",
      "880/880 [==============================] - 0s 166us/step - loss: 24735.4468 - mean_absolute_error: 24735.4468 - val_loss: 27248.0110 - val_mean_absolute_error: 27248.0110\n",
      "Epoch 31/500\n",
      "880/880 [==============================] - 0s 166us/step - loss: 24653.5674 - mean_absolute_error: 24653.5674 - val_loss: 26746.0029 - val_mean_absolute_error: 26746.0029\n",
      "Epoch 32/500\n",
      "880/880 [==============================] - 0s 170us/step - loss: 26287.1137 - mean_absolute_error: 26287.1137 - val_loss: 26891.3977 - val_mean_absolute_error: 26891.3977\n",
      "Epoch 33/500\n",
      "880/880 [==============================] - 0s 175us/step - loss: 25211.7661 - mean_absolute_error: 25211.7661 - val_loss: 28005.1374 - val_mean_absolute_error: 28005.1374\n",
      "Epoch 34/500\n",
      "880/880 [==============================] - 0s 172us/step - loss: 24851.9449 - mean_absolute_error: 24851.9449 - val_loss: 26154.5011 - val_mean_absolute_error: 26154.5011\n",
      "Epoch 35/500\n",
      "880/880 [==============================] - 0s 171us/step - loss: 24505.8623 - mean_absolute_error: 24505.8623 - val_loss: 30026.1989 - val_mean_absolute_error: 30026.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/500\n",
      "880/880 [==============================] - 0s 173us/step - loss: 25239.2029 - mean_absolute_error: 25239.2029 - val_loss: 25860.6023 - val_mean_absolute_error: 25860.6023\n",
      "Epoch 37/500\n",
      "880/880 [==============================] - 0s 174us/step - loss: 25296.2591 - mean_absolute_error: 25296.2591 - val_loss: 29702.8051 - val_mean_absolute_error: 29702.8051\n",
      "Epoch 38/500\n",
      "880/880 [==============================] - 0s 173us/step - loss: 26375.6475 - mean_absolute_error: 26375.6475 - val_loss: 28720.7752 - val_mean_absolute_error: 28720.7752\n",
      "Epoch 39/500\n",
      "880/880 [==============================] - 0s 171us/step - loss: 25402.8697 - mean_absolute_error: 25402.8697 - val_loss: 26985.5462 - val_mean_absolute_error: 26985.5462\n",
      "Epoch 40/500\n",
      "880/880 [==============================] - 0s 172us/step - loss: 24368.1714 - mean_absolute_error: 24368.1714 - val_loss: 25817.3455 - val_mean_absolute_error: 25817.3455\n",
      "Epoch 41/500\n",
      "880/880 [==============================] - 0s 176us/step - loss: 24237.9654 - mean_absolute_error: 24237.9654 - val_loss: 25837.5105 - val_mean_absolute_error: 25837.5105\n",
      "Epoch 42/500\n",
      "880/880 [==============================] - 0s 179us/step - loss: 23774.5715 - mean_absolute_error: 23774.5715 - val_loss: 25987.4813 - val_mean_absolute_error: 25987.4813\n",
      "Epoch 43/500\n",
      "880/880 [==============================] - 0s 181us/step - loss: 23731.9230 - mean_absolute_error: 23731.9230 - val_loss: 25966.0295 - val_mean_absolute_error: 25966.0295\n",
      "Epoch 44/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 23715.8946 - mean_absolute_error: 23715.8946 - val_loss: 25606.0958 - val_mean_absolute_error: 25606.0958\n",
      "Epoch 45/500\n",
      "880/880 [==============================] - 0s 184us/step - loss: 24461.7653 - mean_absolute_error: 24461.7653 - val_loss: 25655.8683 - val_mean_absolute_error: 25655.8683\n",
      "Epoch 46/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 23718.0431 - mean_absolute_error: 23718.0431 - val_loss: 25823.4470 - val_mean_absolute_error: 25823.4470\n",
      "Epoch 47/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 23645.8630 - mean_absolute_error: 23645.8630 - val_loss: 26513.1277 - val_mean_absolute_error: 26513.1277\n",
      "Epoch 48/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 23497.4551 - mean_absolute_error: 23497.4551 - val_loss: 27388.7999 - val_mean_absolute_error: 27388.7999\n",
      "Epoch 49/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 23850.3896 - mean_absolute_error: 23850.3896 - val_loss: 25866.9756 - val_mean_absolute_error: 25866.9756\n",
      "Epoch 50/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 23727.8740 - mean_absolute_error: 23727.8740 - val_loss: 25492.1759 - val_mean_absolute_error: 25492.1759\n",
      "Epoch 51/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 24638.9972 - mean_absolute_error: 24638.9972 - val_loss: 27589.6499 - val_mean_absolute_error: 27589.6499\n",
      "Epoch 52/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 25348.0760 - mean_absolute_error: 25348.0760 - val_loss: 25742.6590 - val_mean_absolute_error: 25742.6590\n",
      "Epoch 53/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 23792.9988 - mean_absolute_error: 23792.9988 - val_loss: 25523.7634 - val_mean_absolute_error: 25523.7634\n",
      "Epoch 54/500\n",
      "880/880 [==============================] - 0s 222us/step - loss: 24924.1662 - mean_absolute_error: 24924.1662 - val_loss: 26764.9128 - val_mean_absolute_error: 26764.9128\n",
      "Epoch 55/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 23725.7692 - mean_absolute_error: 23725.7692 - val_loss: 25379.6522 - val_mean_absolute_error: 25379.6522\n",
      "Epoch 56/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 23801.0936 - mean_absolute_error: 23801.0936 - val_loss: 26527.1634 - val_mean_absolute_error: 26527.1634\n",
      "Epoch 57/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 25548.3124 - mean_absolute_error: 25548.3124 - val_loss: 36214.6330 - val_mean_absolute_error: 36214.6330\n",
      "Epoch 58/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 26163.9259 - mean_absolute_error: 26163.9259 - val_loss: 27218.2480 - val_mean_absolute_error: 27218.2480\n",
      "Epoch 59/500\n",
      "880/880 [==============================] - 0s 240us/step - loss: 24543.9455 - mean_absolute_error: 24543.9455 - val_loss: 25395.5396 - val_mean_absolute_error: 25395.5396\n",
      "Epoch 60/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 23008.0559 - mean_absolute_error: 23008.0559 - val_loss: 25316.2426 - val_mean_absolute_error: 25316.2426\n",
      "Epoch 61/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 23606.8678 - mean_absolute_error: 23606.8678 - val_loss: 26889.8108 - val_mean_absolute_error: 26889.8108\n",
      "Epoch 62/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 23106.0844 - mean_absolute_error: 23106.0844 - val_loss: 25584.9404 - val_mean_absolute_error: 25584.9404\n",
      "Epoch 63/500\n",
      "880/880 [==============================] - 0s 225us/step - loss: 23312.9059 - mean_absolute_error: 23312.9059 - val_loss: 26467.9279 - val_mean_absolute_error: 26467.9279\n",
      "Epoch 64/500\n",
      "880/880 [==============================] - 0s 221us/step - loss: 25209.5190 - mean_absolute_error: 25209.5190 - val_loss: 25251.8928 - val_mean_absolute_error: 25251.8928\n",
      "Epoch 65/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 23084.1502 - mean_absolute_error: 23084.1502 - val_loss: 25275.1975 - val_mean_absolute_error: 25275.1975\n",
      "Epoch 66/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 22658.1233 - mean_absolute_error: 22658.1233 - val_loss: 25865.1532 - val_mean_absolute_error: 25865.1532\n",
      "Epoch 67/500\n",
      "880/880 [==============================] - 0s 228us/step - loss: 23233.6690 - mean_absolute_error: 23233.6690 - val_loss: 26286.6164 - val_mean_absolute_error: 26286.6164\n",
      "Epoch 68/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 23043.5907 - mean_absolute_error: 23043.5907 - val_loss: 26274.1316 - val_mean_absolute_error: 26274.1316\n",
      "Epoch 69/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 23828.0565 - mean_absolute_error: 23828.0565 - val_loss: 29159.4700 - val_mean_absolute_error: 29159.4700\n",
      "Epoch 70/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 23456.7495 - mean_absolute_error: 23456.7495 - val_loss: 26309.7971 - val_mean_absolute_error: 26309.7971\n",
      "Epoch 71/500\n",
      "880/880 [==============================] - 0s 209us/step - loss: 24093.1176 - mean_absolute_error: 24093.1176 - val_loss: 26175.6007 - val_mean_absolute_error: 26175.6007\n",
      "Epoch 72/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 23997.3329 - mean_absolute_error: 23997.3329 - val_loss: 28620.3362 - val_mean_absolute_error: 28620.3362\n",
      "Epoch 73/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 22653.5828 - mean_absolute_error: 22653.5828 - val_loss: 26339.4383 - val_mean_absolute_error: 26339.4383\n",
      "Epoch 74/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 22732.2669 - mean_absolute_error: 22732.2669 - val_loss: 25692.0630 - val_mean_absolute_error: 25692.0630\n",
      "Epoch 75/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 23978.9671 - mean_absolute_error: 23978.9671 - val_loss: 25115.8889 - val_mean_absolute_error: 25115.8889\n",
      "Epoch 76/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 23485.8381 - mean_absolute_error: 23485.8381 - val_loss: 25305.2097 - val_mean_absolute_error: 25305.2097\n",
      "Epoch 77/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 23346.9451 - mean_absolute_error: 23346.9451 - val_loss: 26013.6573 - val_mean_absolute_error: 26013.6573\n",
      "Epoch 78/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 22746.4411 - mean_absolute_error: 22746.4411 - val_loss: 29797.4028 - val_mean_absolute_error: 29797.4028\n",
      "Epoch 79/500\n",
      "880/880 [==============================] - 0s 210us/step - loss: 22889.4382 - mean_absolute_error: 22889.4382 - val_loss: 25200.4060 - val_mean_absolute_error: 25200.4060\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 185us/step - loss: 22799.6164 - mean_absolute_error: 22799.6164 - val_loss: 25488.1201 - val_mean_absolute_error: 25488.1201\n",
      "Epoch 81/500\n",
      "880/880 [==============================] - 0s 183us/step - loss: 23695.3620 - mean_absolute_error: 23695.3620 - val_loss: 25079.1706 - val_mean_absolute_error: 25079.1706\n",
      "Epoch 82/500\n",
      "880/880 [==============================] - 0s 182us/step - loss: 23657.5646 - mean_absolute_error: 23657.5646 - val_loss: 25499.1127 - val_mean_absolute_error: 25499.1127\n",
      "Epoch 83/500\n",
      "880/880 [==============================] - 0s 182us/step - loss: 22787.5042 - mean_absolute_error: 22787.5042 - val_loss: 24966.3743 - val_mean_absolute_error: 24966.3743\n",
      "Epoch 84/500\n",
      "880/880 [==============================] - 0s 182us/step - loss: 23316.3822 - mean_absolute_error: 23316.3822 - val_loss: 28856.1371 - val_mean_absolute_error: 28856.1371\n",
      "Epoch 85/500\n",
      "880/880 [==============================] - 0s 182us/step - loss: 22773.0523 - mean_absolute_error: 22773.0523 - val_loss: 25043.3180 - val_mean_absolute_error: 25043.3180\n",
      "Epoch 86/500\n",
      "880/880 [==============================] - 0s 182us/step - loss: 23421.9513 - mean_absolute_error: 23421.9513 - val_loss: 25651.1589 - val_mean_absolute_error: 25651.1589\n",
      "Epoch 87/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 26063.2463 - mean_absolute_error: 26063.2463 - val_loss: 27582.4963 - val_mean_absolute_error: 27582.4963\n",
      "Epoch 88/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 23874.5279 - mean_absolute_error: 23874.5279 - val_loss: 25946.6667 - val_mean_absolute_error: 25946.6667\n",
      "Epoch 89/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 23814.9539 - mean_absolute_error: 23814.9539 - val_loss: 25838.0113 - val_mean_absolute_error: 25838.0113\n",
      "Epoch 90/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 22428.4257 - mean_absolute_error: 22428.4257 - val_loss: 25165.1650 - val_mean_absolute_error: 25165.1650\n",
      "Epoch 91/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 22311.7901 - mean_absolute_error: 22311.7901 - val_loss: 26498.7840 - val_mean_absolute_error: 26498.7840\n",
      "Epoch 92/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 22794.7801 - mean_absolute_error: 22794.7801 - val_loss: 25073.1043 - val_mean_absolute_error: 25073.1043\n",
      "Epoch 93/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 22574.9999 - mean_absolute_error: 22574.9999 - val_loss: 25638.1769 - val_mean_absolute_error: 25638.1769\n",
      "Epoch 94/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 23003.9285 - mean_absolute_error: 23003.9285 - val_loss: 25809.6576 - val_mean_absolute_error: 25809.6576\n",
      "Epoch 95/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 22127.8746 - mean_absolute_error: 22127.8746 - val_loss: 26606.7147 - val_mean_absolute_error: 26606.7147\n",
      "Epoch 96/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 22605.5819 - mean_absolute_error: 22605.5819 - val_loss: 25007.8047 - val_mean_absolute_error: 25007.8047\n",
      "Epoch 97/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 22595.6973 - mean_absolute_error: 22595.6973 - val_loss: 26165.6927 - val_mean_absolute_error: 26165.6927\n",
      "Epoch 98/500\n",
      "880/880 [==============================] - 0s 215us/step - loss: 22294.4152 - mean_absolute_error: 22294.4152 - val_loss: 24861.4856 - val_mean_absolute_error: 24861.4856\n",
      "Epoch 99/500\n",
      "880/880 [==============================] - 0s 210us/step - loss: 22439.7666 - mean_absolute_error: 22439.7666 - val_loss: 24946.2626 - val_mean_absolute_error: 24946.2626\n",
      "Epoch 100/500\n",
      "880/880 [==============================] - 0s 208us/step - loss: 23000.8020 - mean_absolute_error: 23000.8020 - val_loss: 25110.8228 - val_mean_absolute_error: 25110.8228\n",
      "Epoch 101/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 22504.4562 - mean_absolute_error: 22504.4562 - val_loss: 24678.7108 - val_mean_absolute_error: 24678.7108\n",
      "Epoch 102/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 22014.5304 - mean_absolute_error: 22014.5304 - val_loss: 25024.1401 - val_mean_absolute_error: 25024.1401\n",
      "Epoch 103/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 22720.0869 - mean_absolute_error: 22720.0869 - val_loss: 24798.0655 - val_mean_absolute_error: 24798.0655\n",
      "Epoch 104/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 23095.8262 - mean_absolute_error: 23095.8262 - val_loss: 24913.6011 - val_mean_absolute_error: 24913.6011\n",
      "Epoch 105/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 23872.5401 - mean_absolute_error: 23872.5401 - val_loss: 30172.3910 - val_mean_absolute_error: 30172.3910\n",
      "Epoch 106/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 23842.1268 - mean_absolute_error: 23842.1268 - val_loss: 24560.2653 - val_mean_absolute_error: 24560.2653\n",
      "Epoch 107/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 23327.7178 - mean_absolute_error: 23327.7178 - val_loss: 25828.8379 - val_mean_absolute_error: 25828.8379\n",
      "Epoch 108/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 22548.4902 - mean_absolute_error: 22548.4902 - val_loss: 24872.7934 - val_mean_absolute_error: 24872.7934\n",
      "Epoch 109/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 22277.8693 - mean_absolute_error: 22277.8693 - val_loss: 24704.1103 - val_mean_absolute_error: 24704.1103\n",
      "Epoch 110/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 22481.3613 - mean_absolute_error: 22481.3613 - val_loss: 24521.8632 - val_mean_absolute_error: 24521.8632\n",
      "Epoch 111/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 21913.1663 - mean_absolute_error: 21913.1663 - val_loss: 25260.4815 - val_mean_absolute_error: 25260.4815\n",
      "Epoch 112/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 21738.3061 - mean_absolute_error: 21738.3061 - val_loss: 24791.5730 - val_mean_absolute_error: 24791.5730\n",
      "Epoch 113/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 21770.1390 - mean_absolute_error: 21770.1390 - val_loss: 24552.0236 - val_mean_absolute_error: 24552.0236\n",
      "Epoch 114/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 22839.5222 - mean_absolute_error: 22839.5222 - val_loss: 25178.4961 - val_mean_absolute_error: 25178.4961\n",
      "Epoch 115/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 21714.1333 - mean_absolute_error: 21714.1333 - val_loss: 27026.0425 - val_mean_absolute_error: 27026.0425\n",
      "Epoch 116/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 22117.8555 - mean_absolute_error: 22117.8555 - val_loss: 24794.7985 - val_mean_absolute_error: 24794.7985\n",
      "Epoch 117/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 22909.2664 - mean_absolute_error: 22909.2664 - val_loss: 25415.5357 - val_mean_absolute_error: 25415.5357\n",
      "Epoch 118/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 21825.4428 - mean_absolute_error: 21825.4428 - val_loss: 24231.0177 - val_mean_absolute_error: 24231.0177\n",
      "Epoch 119/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 22217.5502 - mean_absolute_error: 22217.5502 - val_loss: 26765.3803 - val_mean_absolute_error: 26765.3803\n",
      "Epoch 120/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 22337.3600 - mean_absolute_error: 22337.3600 - val_loss: 25118.2998 - val_mean_absolute_error: 25118.2998\n",
      "Epoch 121/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 23132.4886 - mean_absolute_error: 23132.4886 - val_loss: 24341.9440 - val_mean_absolute_error: 24341.9440\n",
      "Epoch 122/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 22283.3306 - mean_absolute_error: 22283.3306 - val_loss: 24884.9106 - val_mean_absolute_error: 24884.9106\n",
      "Epoch 123/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 23006.1591 - mean_absolute_error: 23006.1591 - val_loss: 26181.7551 - val_mean_absolute_error: 26181.7551\n",
      "Epoch 124/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 203us/step - loss: 21557.4834 - mean_absolute_error: 21557.4834 - val_loss: 25873.6290 - val_mean_absolute_error: 25873.6290\n",
      "Epoch 125/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 22296.7879 - mean_absolute_error: 22296.7879 - val_loss: 25305.1370 - val_mean_absolute_error: 25305.1370\n",
      "Epoch 126/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 22636.7140 - mean_absolute_error: 22636.7140 - val_loss: 24644.6852 - val_mean_absolute_error: 24644.6852\n",
      "Epoch 127/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 22558.2166 - mean_absolute_error: 22558.2166 - val_loss: 25764.6733 - val_mean_absolute_error: 25764.6733\n",
      "Epoch 128/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 21604.8968 - mean_absolute_error: 21604.8968 - val_loss: 24254.6327 - val_mean_absolute_error: 24254.6327\n",
      "Epoch 129/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 21842.8938 - mean_absolute_error: 21842.8938 - val_loss: 24863.7233 - val_mean_absolute_error: 24863.7233\n",
      "Epoch 130/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 21213.0949 - mean_absolute_error: 21213.0949 - val_loss: 24075.5047 - val_mean_absolute_error: 24075.5047\n",
      "Epoch 131/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 21900.2918 - mean_absolute_error: 21900.2918 - val_loss: 25221.7659 - val_mean_absolute_error: 25221.7659\n",
      "Epoch 132/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 21890.7351 - mean_absolute_error: 21890.7351 - val_loss: 25393.3554 - val_mean_absolute_error: 25393.3554\n",
      "Epoch 133/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 22700.5749 - mean_absolute_error: 22700.5749 - val_loss: 24003.9929 - val_mean_absolute_error: 24003.9929\n",
      "Epoch 134/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 21360.7457 - mean_absolute_error: 21360.7457 - val_loss: 30469.2582 - val_mean_absolute_error: 30469.2582\n",
      "Epoch 135/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 22536.4469 - mean_absolute_error: 22536.4469 - val_loss: 23932.7866 - val_mean_absolute_error: 23932.7866\n",
      "Epoch 136/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 23043.4252 - mean_absolute_error: 23043.4252 - val_loss: 24799.8555 - val_mean_absolute_error: 24799.8555\n",
      "Epoch 137/500\n",
      "880/880 [==============================] - 0s 220us/step - loss: 21167.8744 - mean_absolute_error: 21167.8744 - val_loss: 24966.7813 - val_mean_absolute_error: 24966.7813\n",
      "Epoch 138/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 21813.2580 - mean_absolute_error: 21813.2580 - val_loss: 23991.6468 - val_mean_absolute_error: 23991.6468\n",
      "Epoch 139/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 21587.8655 - mean_absolute_error: 21587.8655 - val_loss: 26669.9088 - val_mean_absolute_error: 26669.9088\n",
      "Epoch 140/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 22498.7080 - mean_absolute_error: 22498.7080 - val_loss: 24741.3984 - val_mean_absolute_error: 24741.3984\n",
      "Epoch 141/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 21335.9873 - mean_absolute_error: 21335.9873 - val_loss: 24010.3631 - val_mean_absolute_error: 24010.3631\n",
      "Epoch 142/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 21557.1587 - mean_absolute_error: 21557.1587 - val_loss: 27898.9412 - val_mean_absolute_error: 27898.9412\n",
      "Epoch 143/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 22984.6145 - mean_absolute_error: 22984.6145 - val_loss: 25355.6532 - val_mean_absolute_error: 25355.6532\n",
      "Epoch 144/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 21738.0426 - mean_absolute_error: 21738.0426 - val_loss: 24967.7216 - val_mean_absolute_error: 24967.7216\n",
      "Epoch 145/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 21893.0059 - mean_absolute_error: 21893.0059 - val_loss: 24340.0347 - val_mean_absolute_error: 24340.0347\n",
      "Epoch 146/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 21038.4327 - mean_absolute_error: 21038.4327 - val_loss: 29364.4004 - val_mean_absolute_error: 29364.4004\n",
      "Epoch 147/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 22512.7560 - mean_absolute_error: 22512.7560 - val_loss: 27088.7477 - val_mean_absolute_error: 27088.7477\n",
      "Epoch 148/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 22849.5053 - mean_absolute_error: 22849.5053 - val_loss: 26902.2509 - val_mean_absolute_error: 26902.2509\n",
      "Epoch 149/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 23322.4216 - mean_absolute_error: 23322.4216 - val_loss: 24813.7136 - val_mean_absolute_error: 24813.7136\n",
      "Epoch 150/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 21138.2919 - mean_absolute_error: 21138.2919 - val_loss: 23643.2290 - val_mean_absolute_error: 23643.2290\n",
      "Epoch 151/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 21555.1785 - mean_absolute_error: 21555.1785 - val_loss: 28461.2511 - val_mean_absolute_error: 28461.2511\n",
      "Epoch 152/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 21299.2937 - mean_absolute_error: 21299.2937 - val_loss: 23620.1076 - val_mean_absolute_error: 23620.1076\n",
      "Epoch 153/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 21746.7236 - mean_absolute_error: 21746.7236 - val_loss: 24272.9071 - val_mean_absolute_error: 24272.9071\n",
      "Epoch 154/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 20904.8892 - mean_absolute_error: 20904.8892 - val_loss: 23659.2120 - val_mean_absolute_error: 23659.2120\n",
      "Epoch 155/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 20824.4181 - mean_absolute_error: 20824.4181 - val_loss: 25393.8922 - val_mean_absolute_error: 25393.8922\n",
      "Epoch 156/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 21451.7961 - mean_absolute_error: 21451.7961 - val_loss: 24140.6112 - val_mean_absolute_error: 24140.6112\n",
      "Epoch 157/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 20912.3552 - mean_absolute_error: 20912.3552 - val_loss: 23735.7512 - val_mean_absolute_error: 23735.7512\n",
      "Epoch 158/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 20718.2980 - mean_absolute_error: 20718.2980 - val_loss: 23766.4430 - val_mean_absolute_error: 23766.4430\n",
      "Epoch 159/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 21963.1292 - mean_absolute_error: 21963.1292 - val_loss: 26813.7305 - val_mean_absolute_error: 26813.7305\n",
      "Epoch 160/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 21134.6370 - mean_absolute_error: 21134.6370 - val_loss: 23612.0224 - val_mean_absolute_error: 23612.0224\n",
      "Epoch 161/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 21425.3588 - mean_absolute_error: 21425.3588 - val_loss: 24405.7849 - val_mean_absolute_error: 24405.7849\n",
      "Epoch 162/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 20735.0018 - mean_absolute_error: 20735.0018 - val_loss: 23549.2218 - val_mean_absolute_error: 23549.2218\n",
      "Epoch 163/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 20802.4577 - mean_absolute_error: 20802.4577 - val_loss: 24760.5365 - val_mean_absolute_error: 24760.5365\n",
      "Epoch 164/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 22613.0617 - mean_absolute_error: 22613.0617 - val_loss: 25892.1932 - val_mean_absolute_error: 25892.1932\n",
      "Epoch 165/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 21634.1138 - mean_absolute_error: 21634.1138 - val_loss: 23412.0092 - val_mean_absolute_error: 23412.0092\n",
      "Epoch 166/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 21395.1746 - mean_absolute_error: 21395.1746 - val_loss: 25323.8321 - val_mean_absolute_error: 25323.8321\n",
      "Epoch 167/500\n",
      "880/880 [==============================] - 0s 216us/step - loss: 20898.7712 - mean_absolute_error: 20898.7712 - val_loss: 26397.2219 - val_mean_absolute_error: 26397.2219\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 212us/step - loss: 22945.0151 - mean_absolute_error: 22945.0151 - val_loss: 23995.2773 - val_mean_absolute_error: 23995.2773\n",
      "Epoch 169/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 21188.3262 - mean_absolute_error: 21188.3262 - val_loss: 26644.4595 - val_mean_absolute_error: 26644.4595\n",
      "Epoch 170/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 21865.9421 - mean_absolute_error: 21865.9421 - val_loss: 23403.4077 - val_mean_absolute_error: 23403.4077\n",
      "Epoch 171/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 21464.8487 - mean_absolute_error: 21464.8487 - val_loss: 24933.0382 - val_mean_absolute_error: 24933.0382\n",
      "Epoch 172/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 20809.6703 - mean_absolute_error: 20809.6703 - val_loss: 23401.2629 - val_mean_absolute_error: 23401.2629\n",
      "Epoch 173/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 20952.7972 - mean_absolute_error: 20952.7972 - val_loss: 24799.0196 - val_mean_absolute_error: 24799.0196\n",
      "Epoch 174/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 21633.8854 - mean_absolute_error: 21633.8854 - val_loss: 25990.1518 - val_mean_absolute_error: 25990.1518\n",
      "Epoch 175/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 21160.3814 - mean_absolute_error: 21160.3814 - val_loss: 29091.7934 - val_mean_absolute_error: 29091.7934\n",
      "Epoch 176/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 20463.5401 - mean_absolute_error: 20463.5401 - val_loss: 23283.4767 - val_mean_absolute_error: 23283.4767\n",
      "Epoch 177/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 20374.0059 - mean_absolute_error: 20374.0059 - val_loss: 23745.6444 - val_mean_absolute_error: 23745.6444\n",
      "Epoch 178/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 21067.3398 - mean_absolute_error: 21067.3398 - val_loss: 23493.1702 - val_mean_absolute_error: 23493.1702\n",
      "Epoch 179/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 20877.2843 - mean_absolute_error: 20877.2843 - val_loss: 26233.1244 - val_mean_absolute_error: 26233.1244\n",
      "Epoch 180/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 23692.9262 - mean_absolute_error: 23692.9262 - val_loss: 23590.1970 - val_mean_absolute_error: 23590.1970\n",
      "Epoch 181/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 20518.4417 - mean_absolute_error: 20518.4417 - val_loss: 23218.4120 - val_mean_absolute_error: 23218.4120\n",
      "Epoch 182/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 20551.8221 - mean_absolute_error: 20551.8221 - val_loss: 25189.0344 - val_mean_absolute_error: 25189.0344\n",
      "Epoch 183/500\n",
      "880/880 [==============================] - 0s 215us/step - loss: 20069.4209 - mean_absolute_error: 20069.4209 - val_loss: 25236.0331 - val_mean_absolute_error: 25236.0331\n",
      "Epoch 184/500\n",
      "880/880 [==============================] - 0s 208us/step - loss: 20797.0748 - mean_absolute_error: 20797.0748 - val_loss: 22822.7105 - val_mean_absolute_error: 22822.7105\n",
      "Epoch 185/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 20545.7451 - mean_absolute_error: 20545.7451 - val_loss: 28489.7006 - val_mean_absolute_error: 28489.7006\n",
      "Epoch 186/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 20480.2875 - mean_absolute_error: 20480.2875 - val_loss: 24114.9995 - val_mean_absolute_error: 24114.9995\n",
      "Epoch 187/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 20823.7707 - mean_absolute_error: 20823.7707 - val_loss: 24050.6205 - val_mean_absolute_error: 24050.6205\n",
      "Epoch 188/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 19793.3007 - mean_absolute_error: 19793.3007 - val_loss: 23425.1842 - val_mean_absolute_error: 23425.1842\n",
      "Epoch 189/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 19630.1230 - mean_absolute_error: 19630.1230 - val_loss: 22837.3325 - val_mean_absolute_error: 22837.3325\n",
      "Epoch 190/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 20492.1819 - mean_absolute_error: 20492.1819 - val_loss: 25348.2771 - val_mean_absolute_error: 25348.2771\n",
      "Epoch 191/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 21276.6233 - mean_absolute_error: 21276.6233 - val_loss: 23296.3405 - val_mean_absolute_error: 23296.3405\n",
      "Epoch 192/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 20419.2616 - mean_absolute_error: 20419.2616 - val_loss: 23703.0817 - val_mean_absolute_error: 23703.0817\n",
      "Epoch 193/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 20065.8681 - mean_absolute_error: 20065.8681 - val_loss: 25125.1516 - val_mean_absolute_error: 25125.1516\n",
      "Epoch 194/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 20500.1597 - mean_absolute_error: 20500.1597 - val_loss: 24710.1897 - val_mean_absolute_error: 24710.1897\n",
      "Epoch 195/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 20167.0322 - mean_absolute_error: 20167.0322 - val_loss: 24812.4780 - val_mean_absolute_error: 24812.4780\n",
      "Epoch 196/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 19624.4280 - mean_absolute_error: 19624.4280 - val_loss: 23886.3037 - val_mean_absolute_error: 23886.3037\n",
      "Epoch 197/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 20255.4774 - mean_absolute_error: 20255.4774 - val_loss: 23546.3413 - val_mean_absolute_error: 23546.3413\n",
      "Epoch 198/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 20574.2182 - mean_absolute_error: 20574.2182 - val_loss: 23263.2900 - val_mean_absolute_error: 23263.2900\n",
      "Epoch 199/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 20494.1935 - mean_absolute_error: 20494.1935 - val_loss: 22772.1426 - val_mean_absolute_error: 22772.1426\n",
      "Epoch 200/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 19690.4859 - mean_absolute_error: 19690.4859 - val_loss: 24668.9803 - val_mean_absolute_error: 24668.9803\n",
      "Epoch 201/500\n",
      "880/880 [==============================] - 0s 215us/step - loss: 21330.4086 - mean_absolute_error: 21330.4086 - val_loss: 25214.4690 - val_mean_absolute_error: 25214.4690\n",
      "Epoch 202/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 19603.8834 - mean_absolute_error: 19603.8834 - val_loss: 23336.2833 - val_mean_absolute_error: 23336.2833\n",
      "Epoch 203/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 21424.6823 - mean_absolute_error: 21424.6823 - val_loss: 23536.1142 - val_mean_absolute_error: 23536.1142\n",
      "Epoch 204/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 20317.8104 - mean_absolute_error: 20317.8104 - val_loss: 22368.6651 - val_mean_absolute_error: 22368.6651\n",
      "Epoch 205/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 20204.2067 - mean_absolute_error: 20204.2067 - val_loss: 24540.4889 - val_mean_absolute_error: 24540.4889\n",
      "Epoch 206/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 19332.4153 - mean_absolute_error: 19332.4153 - val_loss: 23979.3314 - val_mean_absolute_error: 23979.3314\n",
      "Epoch 207/500\n",
      "880/880 [==============================] - 0s 209us/step - loss: 21519.7297 - mean_absolute_error: 21519.7297 - val_loss: 26038.7650 - val_mean_absolute_error: 26038.7650\n",
      "Epoch 208/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 19404.1496 - mean_absolute_error: 19404.1496 - val_loss: 24437.5438 - val_mean_absolute_error: 24437.5438\n",
      "Epoch 209/500\n",
      "880/880 [==============================] - 0s 212us/step - loss: 20028.7578 - mean_absolute_error: 20028.7578 - val_loss: 22107.0089 - val_mean_absolute_error: 22107.0089\n",
      "Epoch 210/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 20553.4050 - mean_absolute_error: 20553.4050 - val_loss: 22766.7384 - val_mean_absolute_error: 22766.7384\n",
      "Epoch 211/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 20204.4669 - mean_absolute_error: 20204.4669 - val_loss: 23399.1966 - val_mean_absolute_error: 23399.1966\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 203us/step - loss: 19817.7468 - mean_absolute_error: 19817.7468 - val_loss: 26272.6248 - val_mean_absolute_error: 26272.6248\n",
      "Epoch 213/500\n",
      "880/880 [==============================] - 0s 219us/step - loss: 20135.2607 - mean_absolute_error: 20135.2607 - val_loss: 26842.3938 - val_mean_absolute_error: 26842.3938\n",
      "Epoch 214/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 19665.3929 - mean_absolute_error: 19665.3929 - val_loss: 24056.9515 - val_mean_absolute_error: 24056.9515\n",
      "Epoch 215/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 19508.6882 - mean_absolute_error: 19508.6882 - val_loss: 26693.7764 - val_mean_absolute_error: 26693.7764\n",
      "Epoch 216/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 19768.4008 - mean_absolute_error: 19768.4008 - val_loss: 22540.2098 - val_mean_absolute_error: 22540.2098\n",
      "Epoch 217/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 19543.1637 - mean_absolute_error: 19543.1637 - val_loss: 23055.3106 - val_mean_absolute_error: 23055.3106\n",
      "Epoch 218/500\n",
      "880/880 [==============================] - 0s 213us/step - loss: 18783.7705 - mean_absolute_error: 18783.7705 - val_loss: 22269.3963 - val_mean_absolute_error: 22269.3963\n",
      "Epoch 219/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 18746.4382 - mean_absolute_error: 18746.4382 - val_loss: 23569.1562 - val_mean_absolute_error: 23569.1562\n",
      "Epoch 220/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 20187.1317 - mean_absolute_error: 20187.1317 - val_loss: 23482.8722 - val_mean_absolute_error: 23482.8722\n",
      "Epoch 221/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 20012.1428 - mean_absolute_error: 20012.1428 - val_loss: 22336.0359 - val_mean_absolute_error: 22336.0359\n",
      "Epoch 222/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 19857.9202 - mean_absolute_error: 19857.9202 - val_loss: 21817.8449 - val_mean_absolute_error: 21817.8449\n",
      "Epoch 223/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 18746.7815 - mean_absolute_error: 18746.7815 - val_loss: 24133.0396 - val_mean_absolute_error: 24133.0396\n",
      "Epoch 224/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 19504.1560 - mean_absolute_error: 19504.1560 - val_loss: 22192.4952 - val_mean_absolute_error: 22192.4952\n",
      "Epoch 225/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 18624.5837 - mean_absolute_error: 18624.5837 - val_loss: 22654.2495 - val_mean_absolute_error: 22654.2495\n",
      "Epoch 226/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 18373.2611 - mean_absolute_error: 18373.2611 - val_loss: 22608.5614 - val_mean_absolute_error: 22608.5614\n",
      "Epoch 227/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 19228.6077 - mean_absolute_error: 19228.6077 - val_loss: 22194.4898 - val_mean_absolute_error: 22194.4898\n",
      "Epoch 228/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 18614.8621 - mean_absolute_error: 18614.8621 - val_loss: 23699.4578 - val_mean_absolute_error: 23699.4578\n",
      "Epoch 229/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 18838.8191 - mean_absolute_error: 18838.8191 - val_loss: 24280.3055 - val_mean_absolute_error: 24280.3055\n",
      "Epoch 230/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 18967.6035 - mean_absolute_error: 18967.6035 - val_loss: 25193.1147 - val_mean_absolute_error: 25193.1147\n",
      "Epoch 231/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 20092.6987 - mean_absolute_error: 20092.6987 - val_loss: 26083.6086 - val_mean_absolute_error: 26083.6086\n",
      "Epoch 232/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 20409.1755 - mean_absolute_error: 20409.1755 - val_loss: 25440.5382 - val_mean_absolute_error: 25440.5382\n",
      "Epoch 233/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 19745.8241 - mean_absolute_error: 19745.8241 - val_loss: 24383.3499 - val_mean_absolute_error: 24383.3499\n",
      "Epoch 234/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 19064.9006 - mean_absolute_error: 19064.9006 - val_loss: 22267.6587 - val_mean_absolute_error: 22267.6587\n",
      "Epoch 235/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 19089.8828 - mean_absolute_error: 19089.8828 - val_loss: 21617.8192 - val_mean_absolute_error: 21617.8192\n",
      "Epoch 236/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 18754.8413 - mean_absolute_error: 18754.8413 - val_loss: 23292.5939 - val_mean_absolute_error: 23292.5939\n",
      "Epoch 237/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 18718.2993 - mean_absolute_error: 18718.2993 - val_loss: 22478.5199 - val_mean_absolute_error: 22478.5199\n",
      "Epoch 238/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 18689.9423 - mean_absolute_error: 18689.9423 - val_loss: 22519.3292 - val_mean_absolute_error: 22519.3292\n",
      "Epoch 239/500\n",
      "880/880 [==============================] - 0s 215us/step - loss: 19421.3850 - mean_absolute_error: 19421.3850 - val_loss: 21978.2078 - val_mean_absolute_error: 21978.2078\n",
      "Epoch 240/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 18952.2581 - mean_absolute_error: 18952.2581 - val_loss: 21393.1300 - val_mean_absolute_error: 21393.1300\n",
      "Epoch 241/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 19919.3032 - mean_absolute_error: 19919.3032 - val_loss: 21310.5706 - val_mean_absolute_error: 21310.5706\n",
      "Epoch 242/500\n",
      "880/880 [==============================] - 0s 213us/step - loss: 18692.7636 - mean_absolute_error: 18692.7636 - val_loss: 22383.7761 - val_mean_absolute_error: 22383.7761\n",
      "Epoch 243/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 19207.3839 - mean_absolute_error: 19207.3839 - val_loss: 22014.7877 - val_mean_absolute_error: 22014.7877\n",
      "Epoch 244/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 18507.4963 - mean_absolute_error: 18507.4963 - val_loss: 21292.7513 - val_mean_absolute_error: 21292.7513\n",
      "Epoch 245/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 18099.0808 - mean_absolute_error: 18099.0808 - val_loss: 21671.8629 - val_mean_absolute_error: 21671.8629\n",
      "Epoch 246/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 18111.6038 - mean_absolute_error: 18111.6038 - val_loss: 22786.7040 - val_mean_absolute_error: 22786.7040\n",
      "Epoch 247/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 19430.3136 - mean_absolute_error: 19430.3136 - val_loss: 23565.8081 - val_mean_absolute_error: 23565.8081\n",
      "Epoch 248/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 18137.5505 - mean_absolute_error: 18137.5505 - val_loss: 21694.0838 - val_mean_absolute_error: 21694.0838\n",
      "Epoch 249/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 18042.0346 - mean_absolute_error: 18042.0346 - val_loss: 22499.4810 - val_mean_absolute_error: 22499.4810\n",
      "Epoch 250/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 17908.3662 - mean_absolute_error: 17908.3662 - val_loss: 23698.4565 - val_mean_absolute_error: 23698.4565\n",
      "Epoch 251/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 18703.9609 - mean_absolute_error: 18703.9609 - val_loss: 21506.5270 - val_mean_absolute_error: 21506.5270\n",
      "Epoch 252/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 18085.3643 - mean_absolute_error: 18085.3643 - val_loss: 22007.1122 - val_mean_absolute_error: 22007.1122\n",
      "Epoch 253/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 18361.0954 - mean_absolute_error: 18361.0954 - val_loss: 24779.5086 - val_mean_absolute_error: 24779.5086\n",
      "Epoch 254/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 19674.2704 - mean_absolute_error: 19674.2704 - val_loss: 22817.5925 - val_mean_absolute_error: 22817.5925\n",
      "Epoch 255/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 18662.5214 - mean_absolute_error: 18662.5214 - val_loss: 22364.1845 - val_mean_absolute_error: 22364.1845\n",
      "Epoch 256/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 203us/step - loss: 19475.7996 - mean_absolute_error: 19475.7996 - val_loss: 21869.5736 - val_mean_absolute_error: 21869.5736\n",
      "Epoch 257/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 18290.5619 - mean_absolute_error: 18290.5619 - val_loss: 21174.8525 - val_mean_absolute_error: 21174.8525\n",
      "Epoch 258/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 18003.4931 - mean_absolute_error: 18003.4931 - val_loss: 21121.3388 - val_mean_absolute_error: 21121.3388\n",
      "Epoch 259/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 17892.2106 - mean_absolute_error: 17892.2106 - val_loss: 21473.5796 - val_mean_absolute_error: 21473.5796\n",
      "Epoch 260/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 18898.8386 - mean_absolute_error: 18898.8386 - val_loss: 21418.0012 - val_mean_absolute_error: 21418.0012\n",
      "Epoch 261/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 17690.2404 - mean_absolute_error: 17690.2404 - val_loss: 22988.9512 - val_mean_absolute_error: 22988.9512\n",
      "Epoch 262/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 19458.2650 - mean_absolute_error: 19458.2650 - val_loss: 21037.4132 - val_mean_absolute_error: 21037.4132\n",
      "Epoch 263/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 17444.7498 - mean_absolute_error: 17444.7498 - val_loss: 20982.4035 - val_mean_absolute_error: 20982.4035\n",
      "Epoch 264/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 18972.2030 - mean_absolute_error: 18972.2030 - val_loss: 22707.9034 - val_mean_absolute_error: 22707.9034\n",
      "Epoch 265/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 17672.6523 - mean_absolute_error: 17672.6523 - val_loss: 21013.2498 - val_mean_absolute_error: 21013.2498\n",
      "Epoch 266/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 18032.5217 - mean_absolute_error: 18032.5217 - val_loss: 21206.6455 - val_mean_absolute_error: 21206.6455\n",
      "Epoch 267/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 19733.3245 - mean_absolute_error: 19733.3245 - val_loss: 21473.6799 - val_mean_absolute_error: 21473.6799\n",
      "Epoch 268/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 17943.3167 - mean_absolute_error: 17943.3167 - val_loss: 22688.2408 - val_mean_absolute_error: 22688.2408\n",
      "Epoch 269/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 19823.9042 - mean_absolute_error: 19823.9042 - val_loss: 22268.0515 - val_mean_absolute_error: 22268.0515\n",
      "Epoch 270/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 18147.7139 - mean_absolute_error: 18147.7139 - val_loss: 23395.3919 - val_mean_absolute_error: 23395.3919\n",
      "Epoch 271/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 20602.3104 - mean_absolute_error: 20602.3104 - val_loss: 24733.2439 - val_mean_absolute_error: 24733.2439\n",
      "Epoch 272/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 18651.9887 - mean_absolute_error: 18651.9887 - val_loss: 21609.4691 - val_mean_absolute_error: 21609.4691\n",
      "Epoch 273/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 17677.5774 - mean_absolute_error: 17677.5774 - val_loss: 22344.6697 - val_mean_absolute_error: 22344.6697\n",
      "Epoch 274/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 17610.9402 - mean_absolute_error: 17610.9402 - val_loss: 22321.1562 - val_mean_absolute_error: 22321.1562\n",
      "Epoch 275/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 17827.7483 - mean_absolute_error: 17827.7483 - val_loss: 21315.0061 - val_mean_absolute_error: 21315.0061\n",
      "Epoch 276/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 17328.1140 - mean_absolute_error: 17328.1140 - val_loss: 20934.0799 - val_mean_absolute_error: 20934.0799\n",
      "Epoch 277/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 17239.2792 - mean_absolute_error: 17239.2792 - val_loss: 22806.4105 - val_mean_absolute_error: 22806.4105\n",
      "Epoch 278/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 18026.5369 - mean_absolute_error: 18026.5369 - val_loss: 22014.2131 - val_mean_absolute_error: 22014.2131\n",
      "Epoch 279/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 17982.6953 - mean_absolute_error: 17982.6953 - val_loss: 22463.2799 - val_mean_absolute_error: 22463.2799\n",
      "Epoch 280/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 21141.0237 - mean_absolute_error: 21141.0237 - val_loss: 20724.0207 - val_mean_absolute_error: 20724.0207\n",
      "Epoch 281/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 17828.1027 - mean_absolute_error: 17828.1027 - val_loss: 21312.1159 - val_mean_absolute_error: 21312.1159\n",
      "Epoch 282/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 16882.7620 - mean_absolute_error: 16882.7620 - val_loss: 21189.7360 - val_mean_absolute_error: 21189.7360\n",
      "Epoch 283/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 17272.7123 - mean_absolute_error: 17272.7123 - val_loss: 21079.4125 - val_mean_absolute_error: 21079.4125\n",
      "Epoch 284/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 18244.4500 - mean_absolute_error: 18244.4500 - val_loss: 24411.2025 - val_mean_absolute_error: 24411.2025\n",
      "Epoch 285/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 18560.0518 - mean_absolute_error: 18560.0518 - val_loss: 21386.1374 - val_mean_absolute_error: 21386.1374\n",
      "Epoch 286/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 19895.0512 - mean_absolute_error: 19895.0512 - val_loss: 22351.2918 - val_mean_absolute_error: 22351.2918\n",
      "Epoch 287/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 17636.5395 - mean_absolute_error: 17636.5395 - val_loss: 20473.3194 - val_mean_absolute_error: 20473.3194\n",
      "Epoch 288/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 17258.8621 - mean_absolute_error: 17258.8621 - val_loss: 22205.3789 - val_mean_absolute_error: 22205.3789\n",
      "Epoch 289/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 17927.5170 - mean_absolute_error: 17927.5170 - val_loss: 21635.3996 - val_mean_absolute_error: 21635.3996\n",
      "Epoch 290/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 17547.1372 - mean_absolute_error: 17547.1372 - val_loss: 26300.5732 - val_mean_absolute_error: 26300.5732\n",
      "Epoch 291/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 18843.3136 - mean_absolute_error: 18843.3136 - val_loss: 20647.1482 - val_mean_absolute_error: 20647.1482\n",
      "Epoch 292/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 18995.7991 - mean_absolute_error: 18995.7991 - val_loss: 20212.0154 - val_mean_absolute_error: 20212.0154\n",
      "Epoch 293/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 17774.7514 - mean_absolute_error: 17774.7514 - val_loss: 25747.0290 - val_mean_absolute_error: 25747.0290\n",
      "Epoch 294/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 18483.4627 - mean_absolute_error: 18483.4627 - val_loss: 20730.0412 - val_mean_absolute_error: 20730.0412\n",
      "Epoch 295/500\n",
      "880/880 [==============================] - 0s 213us/step - loss: 17069.9284 - mean_absolute_error: 17069.9284 - val_loss: 21268.7603 - val_mean_absolute_error: 21268.7603\n",
      "Epoch 296/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 16881.2942 - mean_absolute_error: 16881.2942 - val_loss: 21126.8622 - val_mean_absolute_error: 21126.8622\n",
      "Epoch 297/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 17422.7766 - mean_absolute_error: 17422.7766 - val_loss: 23032.1006 - val_mean_absolute_error: 23032.1006\n",
      "Epoch 298/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 18261.4275 - mean_absolute_error: 18261.4275 - val_loss: 20865.5339 - val_mean_absolute_error: 20865.5339\n",
      "Epoch 299/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 18761.8800 - mean_absolute_error: 18761.8800 - val_loss: 20531.1905 - val_mean_absolute_error: 20531.1905\n",
      "Epoch 300/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 203us/step - loss: 17324.8150 - mean_absolute_error: 17324.8150 - val_loss: 21380.4236 - val_mean_absolute_error: 21380.4236\n",
      "Epoch 301/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 17707.9405 - mean_absolute_error: 17707.9405 - val_loss: 21645.0240 - val_mean_absolute_error: 21645.0240\n",
      "Epoch 302/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 17563.4262 - mean_absolute_error: 17563.4262 - val_loss: 21713.4184 - val_mean_absolute_error: 21713.4184\n",
      "Epoch 303/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 17071.3777 - mean_absolute_error: 17071.3777 - val_loss: 20769.2347 - val_mean_absolute_error: 20769.2347\n",
      "Epoch 304/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 16877.2593 - mean_absolute_error: 16877.2593 - val_loss: 20533.8721 - val_mean_absolute_error: 20533.8721\n",
      "Epoch 305/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 17121.5442 - mean_absolute_error: 17121.5442 - val_loss: 21054.4032 - val_mean_absolute_error: 21054.4032\n",
      "Epoch 306/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 18279.5381 - mean_absolute_error: 18279.5381 - val_loss: 23461.0240 - val_mean_absolute_error: 23461.0240\n",
      "Epoch 307/500\n",
      "880/880 [==============================] - 0s 212us/step - loss: 18380.2823 - mean_absolute_error: 18380.2823 - val_loss: 21372.9200 - val_mean_absolute_error: 21372.9200\n",
      "Epoch 308/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 17260.3460 - mean_absolute_error: 17260.3460 - val_loss: 21729.8412 - val_mean_absolute_error: 21729.8412\n",
      "Epoch 309/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 17870.7631 - mean_absolute_error: 17870.7631 - val_loss: 21307.1757 - val_mean_absolute_error: 21307.1757\n",
      "Epoch 310/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 17313.0886 - mean_absolute_error: 17313.0886 - val_loss: 21833.3654 - val_mean_absolute_error: 21833.3654\n",
      "Epoch 311/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 17789.0245 - mean_absolute_error: 17789.0245 - val_loss: 25276.4064 - val_mean_absolute_error: 25276.4064\n",
      "Epoch 312/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 17994.4026 - mean_absolute_error: 17994.4026 - val_loss: 28602.2322 - val_mean_absolute_error: 28602.2322\n",
      "Epoch 313/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 19528.5582 - mean_absolute_error: 19528.5582 - val_loss: 22406.1753 - val_mean_absolute_error: 22406.1753\n",
      "Epoch 314/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 17281.1929 - mean_absolute_error: 17281.1929 - val_loss: 21631.0679 - val_mean_absolute_error: 21631.0679\n",
      "Epoch 315/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 16636.9645 - mean_absolute_error: 16636.9645 - val_loss: 24504.6019 - val_mean_absolute_error: 24504.6019\n",
      "Epoch 316/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 17961.6957 - mean_absolute_error: 17961.6957 - val_loss: 20386.7826 - val_mean_absolute_error: 20386.7826\n",
      "Epoch 317/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 17220.9282 - mean_absolute_error: 17220.9282 - val_loss: 21209.1679 - val_mean_absolute_error: 21209.1679\n",
      "Epoch 318/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 17674.6299 - mean_absolute_error: 17674.6299 - val_loss: 20981.5895 - val_mean_absolute_error: 20981.5895\n",
      "Epoch 319/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 16467.7344 - mean_absolute_error: 16467.7344 - val_loss: 21011.4346 - val_mean_absolute_error: 21011.4346\n",
      "Epoch 320/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 16218.0900 - mean_absolute_error: 16218.0900 - val_loss: 22879.2260 - val_mean_absolute_error: 22879.2260\n",
      "Epoch 321/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 16317.3587 - mean_absolute_error: 16317.3587 - val_loss: 20905.2451 - val_mean_absolute_error: 20905.2451\n",
      "Epoch 322/500\n",
      "880/880 [==============================] - 0s 189us/step - loss: 16330.2186 - mean_absolute_error: 16330.2186 - val_loss: 21756.2711 - val_mean_absolute_error: 21756.2711\n",
      "Epoch 323/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 16411.2724 - mean_absolute_error: 16411.2724 - val_loss: 20687.9556 - val_mean_absolute_error: 20687.9556\n",
      "Epoch 324/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 16478.2169 - mean_absolute_error: 16478.2169 - val_loss: 20935.7681 - val_mean_absolute_error: 20935.7681\n",
      "Epoch 325/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 16645.6717 - mean_absolute_error: 16645.6717 - val_loss: 25113.2766 - val_mean_absolute_error: 25113.2766\n",
      "Epoch 326/500\n",
      "880/880 [==============================] - 0s 190us/step - loss: 17638.0390 - mean_absolute_error: 17638.0390 - val_loss: 19579.9706 - val_mean_absolute_error: 19579.9706\n",
      "Epoch 327/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 16449.8361 - mean_absolute_error: 16449.8361 - val_loss: 21490.8939 - val_mean_absolute_error: 21490.8939\n",
      "Epoch 328/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 17455.2312 - mean_absolute_error: 17455.2312 - val_loss: 22044.8521 - val_mean_absolute_error: 22044.8521\n",
      "Epoch 329/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 17881.8672 - mean_absolute_error: 17881.8672 - val_loss: 20637.7263 - val_mean_absolute_error: 20637.7263\n",
      "Epoch 330/500\n",
      "880/880 [==============================] - 0s 187us/step - loss: 18575.1875 - mean_absolute_error: 18575.1875 - val_loss: 20410.6088 - val_mean_absolute_error: 20410.6088\n",
      "Epoch 331/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 16732.2441 - mean_absolute_error: 16732.2441 - val_loss: 20332.9504 - val_mean_absolute_error: 20332.9504\n",
      "Epoch 332/500\n",
      "880/880 [==============================] - 0s 186us/step - loss: 16625.8139 - mean_absolute_error: 16625.8139 - val_loss: 21434.1030 - val_mean_absolute_error: 21434.1030\n",
      "Epoch 333/500\n",
      "880/880 [==============================] - 0s 188us/step - loss: 16394.7524 - mean_absolute_error: 16394.7524 - val_loss: 23762.3332 - val_mean_absolute_error: 23762.3332\n",
      "Epoch 334/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 17371.2596 - mean_absolute_error: 17371.2596 - val_loss: 21023.4512 - val_mean_absolute_error: 21023.4512\n",
      "Epoch 335/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 16385.7315 - mean_absolute_error: 16385.7315 - val_loss: 23155.5980 - val_mean_absolute_error: 23155.5980\n",
      "Epoch 336/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 16782.6386 - mean_absolute_error: 16782.6386 - val_loss: 20457.0372 - val_mean_absolute_error: 20457.0372\n",
      "Epoch 337/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 18377.7346 - mean_absolute_error: 18377.7346 - val_loss: 21377.1596 - val_mean_absolute_error: 21377.1596\n",
      "Epoch 338/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 17715.1776 - mean_absolute_error: 17715.1776 - val_loss: 20486.0064 - val_mean_absolute_error: 20486.0064\n",
      "Epoch 339/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 16903.3030 - mean_absolute_error: 16903.3030 - val_loss: 20585.6509 - val_mean_absolute_error: 20585.6509\n",
      "Epoch 340/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 16369.5680 - mean_absolute_error: 16369.5680 - val_loss: 20926.7083 - val_mean_absolute_error: 20926.7083\n",
      "Epoch 341/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 16744.1234 - mean_absolute_error: 16744.1234 - val_loss: 20754.1102 - val_mean_absolute_error: 20754.1102\n",
      "Epoch 342/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 15952.4661 - mean_absolute_error: 15952.4661 - val_loss: 21556.1864 - val_mean_absolute_error: 21556.1864\n",
      "Epoch 343/500\n",
      "880/880 [==============================] - 0s 212us/step - loss: 16007.1884 - mean_absolute_error: 16007.1884 - val_loss: 19630.0198 - val_mean_absolute_error: 19630.0198\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 213us/step - loss: 16567.4286 - mean_absolute_error: 16567.4286 - val_loss: 20265.4576 - val_mean_absolute_error: 20265.4576\n",
      "Epoch 345/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 16983.8678 - mean_absolute_error: 16983.8678 - val_loss: 19278.9190 - val_mean_absolute_error: 19278.9190\n",
      "Epoch 346/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 16098.0461 - mean_absolute_error: 16098.0461 - val_loss: 21281.1882 - val_mean_absolute_error: 21281.1882\n",
      "Epoch 347/500\n",
      "880/880 [==============================] - 0s 221us/step - loss: 16366.8813 - mean_absolute_error: 16366.8813 - val_loss: 20632.9803 - val_mean_absolute_error: 20632.9803\n",
      "Epoch 348/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 16487.6914 - mean_absolute_error: 16487.6914 - val_loss: 20811.6136 - val_mean_absolute_error: 20811.6136\n",
      "Epoch 349/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 16326.8439 - mean_absolute_error: 16326.8439 - val_loss: 24721.2166 - val_mean_absolute_error: 24721.2166\n",
      "Epoch 350/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 17170.3157 - mean_absolute_error: 17170.3157 - val_loss: 21104.2621 - val_mean_absolute_error: 21104.2621\n",
      "Epoch 351/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 16674.3483 - mean_absolute_error: 16674.3483 - val_loss: 28062.7489 - val_mean_absolute_error: 28062.7489\n",
      "Epoch 352/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 17767.3565 - mean_absolute_error: 17767.3565 - val_loss: 20128.2987 - val_mean_absolute_error: 20128.2987\n",
      "Epoch 353/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 17518.9424 - mean_absolute_error: 17518.9424 - val_loss: 20186.0000 - val_mean_absolute_error: 20186.0000\n",
      "Epoch 354/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 15492.8687 - mean_absolute_error: 15492.8687 - val_loss: 19736.6945 - val_mean_absolute_error: 19736.6945\n",
      "Epoch 355/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 15432.4920 - mean_absolute_error: 15432.4920 - val_loss: 19570.5702 - val_mean_absolute_error: 19570.5702\n",
      "Epoch 356/500\n",
      "880/880 [==============================] - 0s 210us/step - loss: 15955.8596 - mean_absolute_error: 15955.8596 - val_loss: 19727.4401 - val_mean_absolute_error: 19727.4401\n",
      "Epoch 357/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 15618.5485 - mean_absolute_error: 15618.5485 - val_loss: 22402.5054 - val_mean_absolute_error: 22402.5054\n",
      "Epoch 358/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 16299.7081 - mean_absolute_error: 16299.7081 - val_loss: 19670.9305 - val_mean_absolute_error: 19670.9305\n",
      "Epoch 359/500\n",
      "880/880 [==============================] - 0s 191us/step - loss: 15780.8070 - mean_absolute_error: 15780.8070 - val_loss: 21591.0888 - val_mean_absolute_error: 21591.0888\n",
      "Epoch 360/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 16287.4274 - mean_absolute_error: 16287.4274 - val_loss: 20305.8635 - val_mean_absolute_error: 20305.8635\n",
      "Epoch 361/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 15564.2025 - mean_absolute_error: 15564.2025 - val_loss: 23678.5016 - val_mean_absolute_error: 23678.5016\n",
      "Epoch 362/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 17343.8400 - mean_absolute_error: 17343.8400 - val_loss: 20304.2932 - val_mean_absolute_error: 20304.2932\n",
      "Epoch 363/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 16778.3183 - mean_absolute_error: 16778.3183 - val_loss: 20743.6360 - val_mean_absolute_error: 20743.6360\n",
      "Epoch 364/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 17379.5425 - mean_absolute_error: 17379.5425 - val_loss: 23400.9594 - val_mean_absolute_error: 23400.9594\n",
      "Epoch 365/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 15644.1634 - mean_absolute_error: 15644.1634 - val_loss: 19746.2290 - val_mean_absolute_error: 19746.2290\n",
      "Epoch 366/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 15367.2546 - mean_absolute_error: 15367.2546 - val_loss: 20045.4247 - val_mean_absolute_error: 20045.4247\n",
      "Epoch 367/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 15280.5794 - mean_absolute_error: 15280.5794 - val_loss: 19614.8570 - val_mean_absolute_error: 19614.8570\n",
      "Epoch 368/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 16142.2766 - mean_absolute_error: 16142.2766 - val_loss: 22119.6304 - val_mean_absolute_error: 22119.6304\n",
      "Epoch 369/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 16119.2012 - mean_absolute_error: 16119.2012 - val_loss: 19606.2218 - val_mean_absolute_error: 19606.2218\n",
      "Epoch 370/500\n",
      "880/880 [==============================] - 0s 210us/step - loss: 14687.7125 - mean_absolute_error: 14687.7125 - val_loss: 22106.1368 - val_mean_absolute_error: 22106.1368\n",
      "Epoch 371/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 15925.8077 - mean_absolute_error: 15925.8077 - val_loss: 19281.0167 - val_mean_absolute_error: 19281.0167\n",
      "Epoch 372/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 15532.0624 - mean_absolute_error: 15532.0624 - val_loss: 19780.3935 - val_mean_absolute_error: 19780.3935\n",
      "Epoch 373/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 15389.7252 - mean_absolute_error: 15389.7252 - val_loss: 19841.2565 - val_mean_absolute_error: 19841.2565\n",
      "Epoch 374/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 16336.8159 - mean_absolute_error: 16336.8159 - val_loss: 18908.3528 - val_mean_absolute_error: 18908.3528\n",
      "Epoch 375/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 16397.3336 - mean_absolute_error: 16397.3336 - val_loss: 20036.9412 - val_mean_absolute_error: 20036.9412\n",
      "Epoch 376/500\n",
      "880/880 [==============================] - 0s 193us/step - loss: 15676.3358 - mean_absolute_error: 15676.3358 - val_loss: 19383.0496 - val_mean_absolute_error: 19383.0496\n",
      "Epoch 377/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 15786.6500 - mean_absolute_error: 15786.6500 - val_loss: 21337.9009 - val_mean_absolute_error: 21337.9009\n",
      "Epoch 378/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 17369.1158 - mean_absolute_error: 17369.1158 - val_loss: 20114.5998 - val_mean_absolute_error: 20114.5998\n",
      "Epoch 379/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 14921.3786 - mean_absolute_error: 14921.3786 - val_loss: 19567.7373 - val_mean_absolute_error: 19567.7373\n",
      "Epoch 380/500\n",
      "880/880 [==============================] - 0s 208us/step - loss: 15014.1904 - mean_absolute_error: 15014.1904 - val_loss: 18837.5469 - val_mean_absolute_error: 18837.5469\n",
      "Epoch 381/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 15939.1745 - mean_absolute_error: 15939.1745 - val_loss: 23492.1819 - val_mean_absolute_error: 23492.1819\n",
      "Epoch 382/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 15441.3618 - mean_absolute_error: 15441.3618 - val_loss: 19782.0816 - val_mean_absolute_error: 19782.0816\n",
      "Epoch 383/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 16598.0829 - mean_absolute_error: 16598.0829 - val_loss: 25556.0059 - val_mean_absolute_error: 25556.0059\n",
      "Epoch 384/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 15337.1724 - mean_absolute_error: 15337.1724 - val_loss: 19066.3470 - val_mean_absolute_error: 19066.3470\n",
      "Epoch 385/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 15492.0213 - mean_absolute_error: 15492.0213 - val_loss: 19890.9534 - val_mean_absolute_error: 19890.9534\n",
      "Epoch 386/500\n",
      "880/880 [==============================] - 0s 211us/step - loss: 17972.1678 - mean_absolute_error: 17972.1678 - val_loss: 19326.5822 - val_mean_absolute_error: 19326.5822\n",
      "Epoch 387/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 17097.9786 - mean_absolute_error: 17097.9786 - val_loss: 18947.1648 - val_mean_absolute_error: 18947.1648\n",
      "Epoch 388/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 193us/step - loss: 15689.5872 - mean_absolute_error: 15689.5872 - val_loss: 20083.0711 - val_mean_absolute_error: 20083.0711\n",
      "Epoch 389/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 15185.5689 - mean_absolute_error: 15185.5689 - val_loss: 19533.7357 - val_mean_absolute_error: 19533.7357\n",
      "Epoch 390/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 15095.3945 - mean_absolute_error: 15095.3945 - val_loss: 19129.2234 - val_mean_absolute_error: 19129.2234\n",
      "Epoch 391/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 14859.5368 - mean_absolute_error: 14859.5368 - val_loss: 21712.3366 - val_mean_absolute_error: 21712.3366\n",
      "Epoch 392/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 15991.9839 - mean_absolute_error: 15991.9839 - val_loss: 21084.9807 - val_mean_absolute_error: 21084.9807\n",
      "Epoch 393/500\n",
      "880/880 [==============================] - 0s 211us/step - loss: 15665.7258 - mean_absolute_error: 15665.7258 - val_loss: 19130.3546 - val_mean_absolute_error: 19130.3546\n",
      "Epoch 394/500\n",
      "880/880 [==============================] - 0s 211us/step - loss: 15236.2661 - mean_absolute_error: 15236.2661 - val_loss: 18934.8546 - val_mean_absolute_error: 18934.8546\n",
      "Epoch 395/500\n",
      "880/880 [==============================] - 0s 231us/step - loss: 16133.3179 - mean_absolute_error: 16133.3179 - val_loss: 19257.3169 - val_mean_absolute_error: 19257.3169\n",
      "Epoch 396/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 16238.8288 - mean_absolute_error: 16238.8288 - val_loss: 19053.2880 - val_mean_absolute_error: 19053.2880\n",
      "Epoch 397/500\n",
      "880/880 [==============================] - 0s 210us/step - loss: 15422.3683 - mean_absolute_error: 15422.3683 - val_loss: 19056.2270 - val_mean_absolute_error: 19056.2270\n",
      "Epoch 398/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14798.5660 - mean_absolute_error: 14798.5660 - val_loss: 21822.1686 - val_mean_absolute_error: 21822.1686\n",
      "Epoch 399/500\n",
      "880/880 [==============================] - 0s 210us/step - loss: 16109.4815 - mean_absolute_error: 16109.4815 - val_loss: 19145.7825 - val_mean_absolute_error: 19145.7825\n",
      "Epoch 400/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 14988.3066 - mean_absolute_error: 14988.3066 - val_loss: 20263.4405 - val_mean_absolute_error: 20263.4405\n",
      "Epoch 401/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14680.7645 - mean_absolute_error: 14680.7645 - val_loss: 18490.4278 - val_mean_absolute_error: 18490.4278\n",
      "Epoch 402/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 15885.5540 - mean_absolute_error: 15885.5540 - val_loss: 18782.0213 - val_mean_absolute_error: 18782.0213\n",
      "Epoch 403/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 16228.6827 - mean_absolute_error: 16228.6827 - val_loss: 18687.9453 - val_mean_absolute_error: 18687.9453\n",
      "Epoch 404/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 15812.3107 - mean_absolute_error: 15812.3107 - val_loss: 21346.7492 - val_mean_absolute_error: 21346.7492\n",
      "Epoch 405/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 16373.7751 - mean_absolute_error: 16373.7751 - val_loss: 19391.3678 - val_mean_absolute_error: 19391.3678\n",
      "Epoch 406/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 15197.6069 - mean_absolute_error: 15197.6069 - val_loss: 21021.7823 - val_mean_absolute_error: 21021.7823\n",
      "Epoch 407/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 16039.4419 - mean_absolute_error: 16039.4419 - val_loss: 19035.5739 - val_mean_absolute_error: 19035.5739\n",
      "Epoch 408/500\n",
      "880/880 [==============================] - 0s 212us/step - loss: 15122.4097 - mean_absolute_error: 15122.4097 - val_loss: 22284.9520 - val_mean_absolute_error: 22284.9520\n",
      "Epoch 409/500\n",
      "880/880 [==============================] - 0s 208us/step - loss: 14354.4278 - mean_absolute_error: 14354.4278 - val_loss: 20900.7221 - val_mean_absolute_error: 20900.7221\n",
      "Epoch 410/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 14711.5169 - mean_absolute_error: 14711.5169 - val_loss: 22602.0777 - val_mean_absolute_error: 22602.0777\n",
      "Epoch 411/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 15543.8863 - mean_absolute_error: 15543.8863 - val_loss: 20381.7102 - val_mean_absolute_error: 20381.7102\n",
      "Epoch 412/500\n",
      "880/880 [==============================] - 0s 222us/step - loss: 15985.3655 - mean_absolute_error: 15985.3655 - val_loss: 21748.3339 - val_mean_absolute_error: 21748.3339\n",
      "Epoch 413/500\n",
      "880/880 [==============================] - 0s 219us/step - loss: 14844.7554 - mean_absolute_error: 14844.7554 - val_loss: 18319.3376 - val_mean_absolute_error: 18319.3376\n",
      "Epoch 414/500\n",
      "880/880 [==============================] - 0s 209us/step - loss: 15021.7138 - mean_absolute_error: 15021.7138 - val_loss: 19894.6412 - val_mean_absolute_error: 19894.6412\n",
      "Epoch 415/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 15569.6013 - mean_absolute_error: 15569.6013 - val_loss: 18696.6944 - val_mean_absolute_error: 18696.6944\n",
      "Epoch 416/500\n",
      "880/880 [==============================] - 0s 209us/step - loss: 14834.2373 - mean_absolute_error: 14834.2373 - val_loss: 19017.6856 - val_mean_absolute_error: 19017.6856\n",
      "Epoch 417/500\n",
      "880/880 [==============================] - 0s 206us/step - loss: 14735.3244 - mean_absolute_error: 14735.3244 - val_loss: 20746.7219 - val_mean_absolute_error: 20746.7219\n",
      "Epoch 418/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14562.1422 - mean_absolute_error: 14562.1422 - val_loss: 18341.6447 - val_mean_absolute_error: 18341.6447\n",
      "Epoch 419/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 14090.0441 - mean_absolute_error: 14090.0441 - val_loss: 18210.8981 - val_mean_absolute_error: 18210.8981\n",
      "Epoch 420/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14555.3309 - mean_absolute_error: 14555.3309 - val_loss: 18496.3680 - val_mean_absolute_error: 18496.3680\n",
      "Epoch 421/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14395.3917 - mean_absolute_error: 14395.3917 - val_loss: 19634.1988 - val_mean_absolute_error: 19634.1988\n",
      "Epoch 422/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 15668.4500 - mean_absolute_error: 15668.4500 - val_loss: 19494.6273 - val_mean_absolute_error: 19494.6273\n",
      "Epoch 423/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14554.7392 - mean_absolute_error: 14554.7392 - val_loss: 19247.3852 - val_mean_absolute_error: 19247.3852\n",
      "Epoch 424/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 16086.3735 - mean_absolute_error: 16086.3735 - val_loss: 22727.1621 - val_mean_absolute_error: 22727.1621\n",
      "Epoch 425/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 14506.6687 - mean_absolute_error: 14506.6687 - val_loss: 18673.1140 - val_mean_absolute_error: 18673.1140\n",
      "Epoch 426/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 14547.9602 - mean_absolute_error: 14547.9602 - val_loss: 18770.1666 - val_mean_absolute_error: 18770.1666\n",
      "Epoch 427/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 15011.8386 - mean_absolute_error: 15011.8386 - val_loss: 18995.9483 - val_mean_absolute_error: 18995.9483\n",
      "Epoch 428/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 15211.0061 - mean_absolute_error: 15211.0061 - val_loss: 19116.4939 - val_mean_absolute_error: 19116.4939\n",
      "Epoch 429/500\n",
      "880/880 [==============================] - 0s 209us/step - loss: 14799.3824 - mean_absolute_error: 14799.3824 - val_loss: 20892.0454 - val_mean_absolute_error: 20892.0454\n",
      "Epoch 430/500\n",
      "880/880 [==============================] - 0s 207us/step - loss: 13971.9976 - mean_absolute_error: 13971.9976 - val_loss: 20191.8596 - val_mean_absolute_error: 20191.8596\n",
      "Epoch 431/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 15086.0455 - mean_absolute_error: 15086.0455 - val_loss: 23704.7608 - val_mean_absolute_error: 23704.7608\n",
      "Epoch 432/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 206us/step - loss: 14906.9703 - mean_absolute_error: 14906.9703 - val_loss: 19268.0534 - val_mean_absolute_error: 19268.0534\n",
      "Epoch 433/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 14297.4912 - mean_absolute_error: 14297.4912 - val_loss: 19124.4602 - val_mean_absolute_error: 19124.4602\n",
      "Epoch 434/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 17072.4500 - mean_absolute_error: 17072.4500 - val_loss: 19780.0862 - val_mean_absolute_error: 19780.0862\n",
      "Epoch 435/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 15432.7096 - mean_absolute_error: 15432.7096 - val_loss: 19166.3969 - val_mean_absolute_error: 19166.3969\n",
      "Epoch 436/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 14775.5475 - mean_absolute_error: 14775.5475 - val_loss: 19756.8857 - val_mean_absolute_error: 19756.8857\n",
      "Epoch 437/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 14963.1819 - mean_absolute_error: 14963.1819 - val_loss: 19124.7870 - val_mean_absolute_error: 19124.7870\n",
      "Epoch 438/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 15287.5313 - mean_absolute_error: 15287.5313 - val_loss: 18661.0504 - val_mean_absolute_error: 18661.0504\n",
      "Epoch 439/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 14327.6356 - mean_absolute_error: 14327.6356 - val_loss: 18417.2143 - val_mean_absolute_error: 18417.2143\n",
      "Epoch 440/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 13670.2561 - mean_absolute_error: 13670.2561 - val_loss: 19028.3718 - val_mean_absolute_error: 19028.3718\n",
      "Epoch 441/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 14485.8611 - mean_absolute_error: 14485.8611 - val_loss: 19978.1446 - val_mean_absolute_error: 19978.1446\n",
      "Epoch 442/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 15182.5863 - mean_absolute_error: 15182.5863 - val_loss: 19271.2399 - val_mean_absolute_error: 19271.2399\n",
      "Epoch 443/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 14857.8316 - mean_absolute_error: 14857.8316 - val_loss: 19379.7971 - val_mean_absolute_error: 19379.7971\n",
      "Epoch 444/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 13911.7461 - mean_absolute_error: 13911.7461 - val_loss: 18105.5023 - val_mean_absolute_error: 18105.5023\n",
      "Epoch 445/500\n",
      "880/880 [==============================] - 0s 205us/step - loss: 14374.3569 - mean_absolute_error: 14374.3569 - val_loss: 18426.3700 - val_mean_absolute_error: 18426.3700\n",
      "Epoch 446/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 13742.8381 - mean_absolute_error: 13742.8381 - val_loss: 19792.5410 - val_mean_absolute_error: 19792.5410\n",
      "Epoch 447/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 14420.8364 - mean_absolute_error: 14420.8364 - val_loss: 18824.1524 - val_mean_absolute_error: 18824.1524\n",
      "Epoch 448/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 14176.1598 - mean_absolute_error: 14176.1598 - val_loss: 18657.9952 - val_mean_absolute_error: 18657.9952\n",
      "Epoch 449/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 14279.2714 - mean_absolute_error: 14279.2714 - val_loss: 21066.4742 - val_mean_absolute_error: 21066.4742\n",
      "Epoch 450/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 14307.1361 - mean_absolute_error: 14307.1361 - val_loss: 18728.5373 - val_mean_absolute_error: 18728.5373\n",
      "Epoch 451/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 14673.3024 - mean_absolute_error: 14673.3024 - val_loss: 17861.7714 - val_mean_absolute_error: 17861.7714\n",
      "Epoch 452/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 14090.1055 - mean_absolute_error: 14090.1055 - val_loss: 19746.3735 - val_mean_absolute_error: 19746.3735\n",
      "Epoch 453/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 14193.4438 - mean_absolute_error: 14193.4438 - val_loss: 22280.6301 - val_mean_absolute_error: 22280.6301\n",
      "Epoch 454/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 14803.2842 - mean_absolute_error: 14803.2842 - val_loss: 18397.8183 - val_mean_absolute_error: 18397.8183\n",
      "Epoch 455/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 13909.5437 - mean_absolute_error: 13909.5437 - val_loss: 18323.9792 - val_mean_absolute_error: 18323.9792\n",
      "Epoch 456/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 14527.6245 - mean_absolute_error: 14527.6245 - val_loss: 25848.6745 - val_mean_absolute_error: 25848.6745\n",
      "Epoch 457/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 15111.3527 - mean_absolute_error: 15111.3527 - val_loss: 18852.7145 - val_mean_absolute_error: 18852.7145\n",
      "Epoch 458/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 13632.6076 - mean_absolute_error: 13632.6076 - val_loss: 21863.4892 - val_mean_absolute_error: 21863.4892\n",
      "Epoch 459/500\n",
      "880/880 [==============================] - 0s 194us/step - loss: 13783.0605 - mean_absolute_error: 13783.0605 - val_loss: 18285.9795 - val_mean_absolute_error: 18285.9795\n",
      "Epoch 460/500\n",
      "880/880 [==============================] - 0s 192us/step - loss: 13657.7935 - mean_absolute_error: 13657.7935 - val_loss: 18765.3529 - val_mean_absolute_error: 18765.3529\n",
      "Epoch 461/500\n",
      "880/880 [==============================] - 0s 213us/step - loss: 13663.2230 - mean_absolute_error: 13663.2230 - val_loss: 18398.5050 - val_mean_absolute_error: 18398.5050\n",
      "Epoch 462/500\n",
      "880/880 [==============================] - 0s 195us/step - loss: 15117.0329 - mean_absolute_error: 15117.0329 - val_loss: 18296.6486 - val_mean_absolute_error: 18296.6486\n",
      "Epoch 463/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 14626.9279 - mean_absolute_error: 14626.9279 - val_loss: 19083.2473 - val_mean_absolute_error: 19083.2473\n",
      "Epoch 464/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 16551.1672 - mean_absolute_error: 16551.1672 - val_loss: 20448.7369 - val_mean_absolute_error: 20448.7369\n",
      "Epoch 465/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 15521.5237 - mean_absolute_error: 15521.5237 - val_loss: 18241.3896 - val_mean_absolute_error: 18241.3896\n",
      "Epoch 466/500\n",
      "880/880 [==============================] - 0s 199us/step - loss: 14094.1952 - mean_absolute_error: 14094.1952 - val_loss: 18361.7520 - val_mean_absolute_error: 18361.7520\n",
      "Epoch 467/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 14843.2972 - mean_absolute_error: 14843.2972 - val_loss: 19103.2630 - val_mean_absolute_error: 19103.2630\n",
      "Epoch 468/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 13299.4398 - mean_absolute_error: 13299.4398 - val_loss: 19101.0988 - val_mean_absolute_error: 19101.0988\n",
      "Epoch 469/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 13025.6636 - mean_absolute_error: 13025.6636 - val_loss: 18464.1653 - val_mean_absolute_error: 18464.1653\n",
      "Epoch 470/500\n",
      "880/880 [==============================] - 0s 215us/step - loss: 13390.5554 - mean_absolute_error: 13390.5554 - val_loss: 19009.0881 - val_mean_absolute_error: 19009.0881\n",
      "Epoch 471/500\n",
      "880/880 [==============================] - 0s 212us/step - loss: 15684.7962 - mean_absolute_error: 15684.7962 - val_loss: 18010.8885 - val_mean_absolute_error: 18010.8885\n",
      "Epoch 472/500\n",
      "880/880 [==============================] - 0s 213us/step - loss: 14391.6528 - mean_absolute_error: 14391.6528 - val_loss: 19297.6423 - val_mean_absolute_error: 19297.6423\n",
      "Epoch 473/500\n",
      "880/880 [==============================] - 0s 217us/step - loss: 13773.9032 - mean_absolute_error: 13773.9032 - val_loss: 20223.5775 - val_mean_absolute_error: 20223.5775\n",
      "Epoch 474/500\n",
      "880/880 [==============================] - 0s 211us/step - loss: 15819.8536 - mean_absolute_error: 15819.8536 - val_loss: 18864.7350 - val_mean_absolute_error: 18864.7350\n",
      "Epoch 475/500\n",
      "880/880 [==============================] - 0s 213us/step - loss: 14692.4726 - mean_absolute_error: 14692.4726 - val_loss: 18488.2782 - val_mean_absolute_error: 18488.2782\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 210us/step - loss: 13740.8373 - mean_absolute_error: 13740.8373 - val_loss: 18306.1946 - val_mean_absolute_error: 18306.1946\n",
      "Epoch 477/500\n",
      "880/880 [==============================] - 0s 204us/step - loss: 13320.7997 - mean_absolute_error: 13320.7997 - val_loss: 17886.6507 - val_mean_absolute_error: 17886.6507\n",
      "Epoch 478/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 13807.9258 - mean_absolute_error: 13807.9258 - val_loss: 19237.5511 - val_mean_absolute_error: 19237.5511\n",
      "Epoch 479/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 13846.2062 - mean_absolute_error: 13846.2062 - val_loss: 18724.9945 - val_mean_absolute_error: 18724.9945\n",
      "Epoch 480/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 13399.6348 - mean_absolute_error: 13399.6348 - val_loss: 18524.3081 - val_mean_absolute_error: 18524.3081\n",
      "Epoch 481/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 13628.0074 - mean_absolute_error: 13628.0074 - val_loss: 18632.9794 - val_mean_absolute_error: 18632.9794\n",
      "Epoch 482/500\n",
      "880/880 [==============================] - 0s 201us/step - loss: 14408.6532 - mean_absolute_error: 14408.6532 - val_loss: 19264.5425 - val_mean_absolute_error: 19264.5425\n",
      "Epoch 483/500\n",
      "880/880 [==============================] - 0s 203us/step - loss: 14133.3141 - mean_absolute_error: 14133.3141 - val_loss: 19835.9973 - val_mean_absolute_error: 19835.9973\n",
      "Epoch 484/500\n",
      "880/880 [==============================] - 0s 202us/step - loss: 14240.0115 - mean_absolute_error: 14240.0115 - val_loss: 20412.5569 - val_mean_absolute_error: 20412.5569\n",
      "Epoch 485/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 13300.6713 - mean_absolute_error: 13300.6713 - val_loss: 18806.6084 - val_mean_absolute_error: 18806.6084\n",
      "Epoch 486/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 13218.5511 - mean_absolute_error: 13218.5511 - val_loss: 18291.9008 - val_mean_absolute_error: 18291.9008\n",
      "Epoch 487/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 14733.1492 - mean_absolute_error: 14733.1492 - val_loss: 19240.2347 - val_mean_absolute_error: 19240.2347\n",
      "Epoch 488/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 14646.0672 - mean_absolute_error: 14646.0672 - val_loss: 20691.2045 - val_mean_absolute_error: 20691.2045\n",
      "Epoch 489/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 13598.7418 - mean_absolute_error: 13598.7418 - val_loss: 18895.9586 - val_mean_absolute_error: 18895.9586\n",
      "Epoch 490/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 13832.9323 - mean_absolute_error: 13832.9323 - val_loss: 18532.8992 - val_mean_absolute_error: 18532.8992\n",
      "Epoch 491/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 13500.2837 - mean_absolute_error: 13500.2837 - val_loss: 18630.3534 - val_mean_absolute_error: 18630.3534\n",
      "Epoch 492/500\n",
      "880/880 [==============================] - 0s 198us/step - loss: 14092.5923 - mean_absolute_error: 14092.5923 - val_loss: 18535.9308 - val_mean_absolute_error: 18535.9308\n",
      "Epoch 493/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 14554.1133 - mean_absolute_error: 14554.1133 - val_loss: 18271.6873 - val_mean_absolute_error: 18271.6873\n",
      "Epoch 494/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 14075.2134 - mean_absolute_error: 14075.2134 - val_loss: 19477.1729 - val_mean_absolute_error: 19477.1729\n",
      "Epoch 495/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 14028.6576 - mean_absolute_error: 14028.6576 - val_loss: 23666.0860 - val_mean_absolute_error: 23666.0860\n",
      "Epoch 496/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 14642.8957 - mean_absolute_error: 14642.8957 - val_loss: 18930.7763 - val_mean_absolute_error: 18930.7763\n",
      "Epoch 497/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 14261.9272 - mean_absolute_error: 14261.9272 - val_loss: 18807.1525 - val_mean_absolute_error: 18807.1525\n",
      "Epoch 498/500\n",
      "880/880 [==============================] - 0s 200us/step - loss: 13620.6099 - mean_absolute_error: 13620.6099 - val_loss: 19038.5924 - val_mean_absolute_error: 19038.5924\n",
      "Epoch 499/500\n",
      "880/880 [==============================] - 0s 196us/step - loss: 14945.1627 - mean_absolute_error: 14945.1627 - val_loss: 21130.2558 - val_mean_absolute_error: 21130.2558\n",
      "Epoch 500/500\n",
      "880/880 [==============================] - 0s 197us/step - loss: 15648.5352 - mean_absolute_error: 15648.5352 - val_loss: 17957.9061 - val_mean_absolute_error: 17957.9061\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train, Y_train, epochs=500, batch_size=32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65775.1  ]\n",
      " [117002.836]\n",
      " [129539.96 ]\n",
      " [123143.125]\n",
      " [116245.24 ]\n",
      " [313014.25 ]\n",
      " [177392.94 ]\n",
      " [215261.   ]\n",
      " [160438.39 ]\n",
      " [298283.12 ]\n",
      " [161715.78 ]\n",
      " [166250.42 ]\n",
      " [108230.71 ]\n",
      " [126243.04 ]\n",
      " [117033.945]\n",
      " [262292.47 ]\n",
      " [150341.97 ]\n",
      " [126338.88 ]\n",
      " [143568.53 ]\n",
      " [111836.38 ]\n",
      " [ 98698.01 ]\n",
      " [191427.89 ]\n",
      " [104306.95 ]\n",
      " [ 95161.03 ]\n",
      " [142864.97 ]\n",
      " [127880.34 ]\n",
      " [188836.75 ]\n",
      " [215468.28 ]\n",
      " [205630.31 ]\n",
      " [122841.016]\n",
      " [180109.1  ]\n",
      " [107322.125]\n",
      " [162915.5  ]\n",
      " [206137.67 ]\n",
      " [159470.7  ]\n",
      " [ 93413.52 ]\n",
      " [113071.42 ]\n",
      " [ 80237.48 ]\n",
      " [214573.75 ]\n",
      " [115979.35 ]\n",
      " [112101.37 ]\n",
      " [195898.39 ]\n",
      " [333930.72 ]\n",
      " [107162.305]\n",
      " [ 93788.914]\n",
      " [123356.66 ]\n",
      " [159537.06 ]\n",
      " [155371.72 ]\n",
      " [ 99099.13 ]\n",
      " [143351.66 ]\n",
      " [105247.08 ]\n",
      " [181494.6  ]\n",
      " [168220.5  ]\n",
      " [111617.43 ]\n",
      " [207257.14 ]\n",
      " [182860.34 ]\n",
      " [163426.12 ]\n",
      " [212408.53 ]\n",
      " [216788.56 ]\n",
      " [163710.14 ]\n",
      " [146241.   ]\n",
      " [238454.03 ]\n",
      " [118052.34 ]\n",
      " [143193.12 ]\n",
      " [195798.19 ]\n",
      " [206447.66 ]\n",
      " [204927.89 ]\n",
      " [172143.81 ]\n",
      " [187526.25 ]\n",
      " [399276.88 ]\n",
      " [151087.53 ]\n",
      " [201669.19 ]\n",
      " [152194.25 ]\n",
      " [175117.4  ]\n",
      " [184968.94 ]\n",
      " [299507.34 ]\n",
      " [120850.48 ]\n",
      " [104413.54 ]\n",
      " [117860.77 ]\n",
      " [ 80586.46 ]\n",
      " [275806.6  ]\n",
      " [227756.75 ]\n",
      " [471308.28 ]\n",
      " [156302.42 ]\n",
      " [293441.4  ]\n",
      " [106542.305]\n",
      " [129251.28 ]\n",
      " [231019.75 ]\n",
      " [174471.34 ]\n",
      " [162627.25 ]\n",
      " [255880.72 ]\n",
      " [161692.62 ]\n",
      " [127707.15 ]\n",
      " [149764.22 ]\n",
      " [149139.7  ]\n",
      " [158111.47 ]\n",
      " [193727.62 ]\n",
      " [155779.94 ]\n",
      " [159621.17 ]\n",
      " [140608.48 ]\n",
      " [ 94100.29 ]\n",
      " [181126.3  ]\n",
      " [111244.766]\n",
      " [216965.5  ]\n",
      " [133528.5  ]\n",
      " [264564.38 ]\n",
      " [117443.36 ]\n",
      " [191802.03 ]\n",
      " [128065.79 ]\n",
      " [261230.55 ]\n",
      " [237444.92 ]\n",
      " [173195.08 ]\n",
      " [ 89099.805]\n",
      " [125429.77 ]\n",
      " [124217.195]\n",
      " [110571.125]\n",
      " [123227.94 ]\n",
      " [192373.03 ]\n",
      " [ 59070.94 ]\n",
      " [ 74322.76 ]\n",
      " [111118.71 ]\n",
      " [133388.89 ]\n",
      " [155711.05 ]\n",
      " [221401.84 ]\n",
      " [169326.   ]\n",
      " [133062.69 ]\n",
      " [197466.4  ]\n",
      " [139341.6  ]\n",
      " [338914.97 ]\n",
      " [136929.4  ]\n",
      " [151284.55 ]\n",
      " [133935.34 ]\n",
      " [ 95768.73 ]\n",
      " [127244.93 ]\n",
      " [134040.56 ]\n",
      " [155140.38 ]\n",
      " [155727.06 ]\n",
      " [196092.86 ]\n",
      " [144288.6  ]\n",
      " [209161.88 ]\n",
      " [175428.77 ]\n",
      " [227734.48 ]\n",
      " [141583.72 ]\n",
      " [374214.28 ]\n",
      " [155529.2  ]\n",
      " [184369.33 ]\n",
      " [165487.7  ]\n",
      " [138026.62 ]\n",
      " [148141.89 ]\n",
      " [107636.07 ]\n",
      " [295542.84 ]\n",
      " [186758.45 ]\n",
      " [101807.76 ]\n",
      " [202890.31 ]\n",
      " [169454.3  ]\n",
      " [121422.51 ]\n",
      " [299996.8  ]\n",
      " [ 81816.51 ]\n",
      " [151420.12 ]\n",
      " [139624.06 ]\n",
      " [178946.62 ]\n",
      " [122608.99 ]\n",
      " [155521.77 ]\n",
      " [153999.89 ]\n",
      " [171503.38 ]\n",
      " [164871.03 ]\n",
      " [140118.92 ]\n",
      " [310057.34 ]\n",
      " [268909.1  ]\n",
      " [133779.75 ]\n",
      " [190533.75 ]\n",
      " [155556.14 ]\n",
      " [130608.68 ]\n",
      " [152882.66 ]\n",
      " [121973.47 ]\n",
      " [148210.6  ]\n",
      " [161219.31 ]\n",
      " [172933.19 ]\n",
      " [209574.4  ]\n",
      " [ 88879.6  ]\n",
      " [199165.22 ]\n",
      " [165040.08 ]\n",
      " [132689.44 ]\n",
      " [162389.42 ]\n",
      " [189905.72 ]\n",
      " [127101.88 ]\n",
      " [143793.03 ]\n",
      " [205992.67 ]\n",
      " [243723.25 ]\n",
      " [228490.69 ]\n",
      " [151787.8  ]\n",
      " [114334.12 ]\n",
      " [142169.22 ]\n",
      " [158747.97 ]\n",
      " [106000.586]\n",
      " [134756.28 ]\n",
      " [135312.3  ]\n",
      " [116454.26 ]\n",
      " [529440.44 ]\n",
      " [166030.25 ]\n",
      " [197235.61 ]\n",
      " [144329.38 ]\n",
      " [288660.3  ]\n",
      " [215986.17 ]\n",
      " [144553.97 ]\n",
      " [310962.28 ]\n",
      " [180971.69 ]\n",
      " [126618.3  ]\n",
      " [139206.3  ]\n",
      " [152971.33 ]\n",
      " [233333.73 ]\n",
      " [180601.84 ]\n",
      " [330536.5  ]\n",
      " [350586.84 ]\n",
      " [118106.805]\n",
      " [179354.69 ]\n",
      " [224201.3  ]\n",
      " [187829.16 ]\n",
      " [276415.12 ]\n",
      " [112684.266]\n",
      " [162877.25 ]\n",
      " [ 64156.977]\n",
      " [192039.34 ]\n",
      " [ 85956.52 ]\n",
      " [243623.25 ]\n",
      " [ 62803.375]\n",
      " [ 75400.64 ]\n",
      " [115620.445]\n",
      " [193391.75 ]\n",
      " [156847.55 ]\n",
      " [220522.69 ]\n",
      " [120068.93 ]\n",
      " [105003.79 ]\n",
      " [125504.31 ]\n",
      " [112568.73 ]\n",
      " [155368.42 ]\n",
      " [186430.94 ]\n",
      " [ 65708.32 ]\n",
      " [203387.22 ]\n",
      " [112330.63 ]\n",
      " [101162.62 ]\n",
      " [148760.69 ]\n",
      " [240997.33 ]\n",
      " [139690.84 ]\n",
      " [160978.12 ]\n",
      " [106572.97 ]\n",
      " [266124.88 ]\n",
      " [248649.   ]\n",
      " [229065.16 ]\n",
      " [152007.67 ]\n",
      " [220015.44 ]\n",
      " [164488.23 ]\n",
      " [113986.66 ]\n",
      " [435585.03 ]\n",
      " [219272.6  ]\n",
      " [164022.06 ]\n",
      " [104722.805]\n",
      " [136514.4  ]\n",
      " [167125.12 ]\n",
      " [297854.25 ]\n",
      " [198606.2  ]\n",
      " [207300.19 ]\n",
      " [137545.56 ]\n",
      " [151018.73 ]\n",
      " [122806.37 ]\n",
      " [178278.42 ]\n",
      " [177548.11 ]\n",
      " [142254.06 ]\n",
      " [124582.24 ]\n",
      " [201918.69 ]\n",
      " [122421.04 ]\n",
      " [157392.36 ]\n",
      " [230326.6  ]\n",
      " [443980.62 ]\n",
      " [226884.66 ]\n",
      " [221876.3  ]\n",
      " [ 82765.086]\n",
      " [134737.31 ]\n",
      " [ 86918.54 ]\n",
      " [ 86657.71 ]\n",
      " [185076.67 ]\n",
      " [140669.4  ]\n",
      " [139788.03 ]\n",
      " [108973.195]\n",
      " [ 96659.52 ]\n",
      " [161367.69 ]\n",
      " [160613.84 ]\n",
      " [279773.7  ]\n",
      " [120664.25 ]\n",
      " [200150.36 ]\n",
      " [173285.   ]\n",
      " [109454.11 ]\n",
      " [134822.94 ]\n",
      " [212432.25 ]\n",
      " [252145.28 ]\n",
      " [209679.1  ]\n",
      " [126427.78 ]\n",
      " [150060.44 ]\n",
      " [154865.   ]\n",
      " [ 97342.57 ]\n",
      " [161492.14 ]\n",
      " [178465.72 ]\n",
      " [238235.5  ]\n",
      " [113894.97 ]\n",
      " [221213.12 ]\n",
      " [105140.195]\n",
      " [105137.32 ]\n",
      " [123231.23 ]\n",
      " [200784.8  ]\n",
      " [185417.4  ]\n",
      " [148053.92 ]\n",
      " [ 76928.09 ]\n",
      " [265875.5  ]\n",
      " [161004.7  ]\n",
      " [217091.92 ]\n",
      " [127440.68 ]\n",
      " [281243.2  ]\n",
      " [132274.55 ]\n",
      " [195495.94 ]\n",
      " [168179.02 ]\n",
      " [151023.44 ]\n",
      " [123011.   ]\n",
      " [175980.47 ]\n",
      " [143467.38 ]\n",
      " [154228.1  ]\n",
      " [247917.5  ]\n",
      " [133480.69 ]\n",
      " [ 94591.92 ]\n",
      " [164537.94 ]\n",
      " [189223.45 ]\n",
      " [119860.016]\n",
      " [ 95671.586]\n",
      " [163728.05 ]\n",
      " [148831.92 ]\n",
      " [154250.69 ]\n",
      " [103822.055]\n",
      " [410558.88 ]\n",
      " [132646.36 ]\n",
      " [148039.81 ]\n",
      " [180059.53 ]\n",
      " [125657.14 ]\n",
      " [260375.42 ]\n",
      " [104673.07 ]\n",
      " [183238.66 ]\n",
      " [109443.85 ]\n",
      " [141205.25 ]\n",
      " [232893.62 ]\n",
      " [122995.21 ]\n",
      " [ 72051.3  ]\n",
      " [147776.16 ]\n",
      " [220785.8  ]\n",
      " [111735.2  ]\n",
      " [122437.85 ]\n",
      " [169362.22 ]\n",
      " [158847.22 ]\n",
      " [196062.4  ]\n",
      " [183533.25 ]\n",
      " [140262.3  ]\n",
      " [175067.2  ]]\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=X_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id=[]\n",
    "pred=[]\n",
    "mean=np.mean(predictions)\n",
    "for i in range(len(Z)-1):\n",
    "    if(Z[i]+1==Z[i+1]):\n",
    "        Id.append(Z[i])\n",
    "        pred.append(int(predictions[i][0]))\n",
    "    else:\n",
    "        Id.append(Z[i]+1)\n",
    "        pred.append(mean)\n",
    "Id.append(Z[len(Z)-1])\n",
    "pred.append(predictions[len(Z)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={\"Id\" : Id,\"SalePrice\": pred}\n",
    "df = pd.DataFrame(dict)  \n",
    "df.to_csv('predict_price.csv',index_label=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
